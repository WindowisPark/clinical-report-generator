import streamlit as st
import os
import re
import io
import yaml
import pandas as pd
import json
import google.generativeai as genai
from datetime import date, timedelta
from jinja2 import Template

# Import clinical trial agent
try:
    from clinical_trial_agent import ClinicalTrialAgent
    CLINICAL_TRIAL_AVAILABLE = True
except ImportError:
    CLINICAL_TRIAL_AVAILABLE = False

# Import queryable criteria analyzer
try:
    from queryable_criteria_analyzer import QueryableCriteriaAnalyzer, QueryabilityLevel
    QUERYABLE_CRITERIA_AVAILABLE = True
except ImportError:
    QUERYABLE_CRITERIA_AVAILABLE = False

# --- 1. Helper Functions ---

def parse_criteria_text(full_text):
    """
    ì „ì²´ í…ìŠ¤íŠ¸ì—ì„œ ì„ ì •ê¸°ì¤€ê³¼ ì œì™¸ê¸°ì¤€ì„ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜
    """
    import re

    # í…ìŠ¤íŠ¸ë¥¼ ì¤„ë³„ë¡œ ë¶„ë¦¬
    lines = full_text.split('\n')

    inclusion_lines = []
    exclusion_lines = []
    current_section = None

    for line in lines:
        line = line.strip()
        if not line:
            continue

        # ì„ ì •ê¸°ì¤€ ì„¹ì…˜ ì‹œì‘ ê°ì§€
        if re.search(r'(ì„ ì •|í¬í•¨|inclusion).*ê¸°ì¤€', line, re.IGNORECASE):
            current_section = 'inclusion'
            continue
        # ì œì™¸ê¸°ì¤€ ì„¹ì…˜ ì‹œì‘ ê°ì§€
        elif re.search(r'(ì œì™¸|exclusion).*ê¸°ì¤€', line, re.IGNORECASE):
            current_section = 'exclusion'
            continue
        # ì„ìƒì‹œí—˜ëª…ì´ë‚˜ ê¸°íƒ€ í—¤ë” ìŠ¤í‚µ
        elif re.search(r'(ì„ìƒì‹œí—˜|ì—°êµ¬|ì œëª©|title)', line, re.IGNORECASE):
            current_section = None
            continue

        # í˜„ì¬ ì„¹ì…˜ì— ë”°ë¼ ë¼ì¸ ì¶”ê°€
        if current_section == 'inclusion':
            # ë²ˆí˜¸ë‚˜ ë¶ˆë¦¿ í¬ì¸íŠ¸ ì œê±°
            clean_line = re.sub(r'^[\d\.\-\*\â€¢\s]+', '', line)
            if clean_line:
                inclusion_lines.append(clean_line)
        elif current_section == 'exclusion':
            # ë²ˆí˜¸ë‚˜ ë¶ˆë¦¿ í¬ì¸íŠ¸ ì œê±°
            clean_line = re.sub(r'^[\d\.\-\*\â€¢\s]+', '', line)
            if clean_line:
                exclusion_lines.append(clean_line)

    # ê²°ê³¼ ì¡°í•©
    inclusion_text = '\n'.join(inclusion_lines) if inclusion_lines else "ì„ ì •ê¸°ì¤€ì´ ëª…ì‹œë˜ì§€ ì•ŠìŒ"
    exclusion_text = '\n'.join(exclusion_lines) if exclusion_lines else "ì œì™¸ê¸°ì¤€ì´ ëª…ì‹œë˜ì§€ ì•ŠìŒ"

    return inclusion_text, exclusion_text

@st.cache_data
def load_recipes():
    """Load all recipe YAML files from the recipes directory."""
    recipe_dir = "recipes"
    recipes = []
    if not os.path.exists(recipe_dir):
        st.error(f"Recipe directory '{recipe_dir}' not found.")
        return recipes
        
    for subdir, _, files in os.walk(recipe_dir):
        for file in files:
            if file.endswith(".yaml"):
                file_path = os.path.join(subdir, file)
                with open(file_path, "r", encoding="utf-8") as f:
                    try:
                        recipe = yaml.safe_load(f)
                        if recipe and 'name' in recipe:
                            recipe['sql_file_path'] = file_path.replace(".yaml", ".sql")
                            recipes.append(recipe)
                    except yaml.YAMLError as e:
                        st.error(f"Error loading YAML file {file_path}: {e}")
    return recipes

@st.cache_data
def load_data_dictionary():
    """Load the data dictionary CSV file."""
    dict_path = "notion_columns_improved.csv"
    if os.path.exists(dict_path):
        return pd.read_csv(dict_path)
    return None

def get_sql_from_recipe(recipe):
    """Get the SQL query content from a recipe's SQL file."""
    try:
        with open(recipe['sql_file_path'], "r", encoding="utf-8") as f:
            return f.read()
    except FileNotFoundError:
        return f"Error: SQL file not found at {recipe['sql_file_path']}"
    except Exception as e:
        return f"An error occurred: {e}"

def fill_sql_parameters(sql_template, params):
    """Renders the SQL template using Jinja2 to handle complex logic and special placeholders."""
    render_params = (params or {}).copy()

    for key, value in render_params.items():
        if isinstance(value, str):
            if value == '[DEFAULT_3_YEARS_AGO]':
                three_years_ago = date.today() - timedelta(days=3*365)
                render_params[key] = three_years_ago.strftime('%Y-%m-%d')
            elif value == '[CURRENT_DATE]':
                render_params[key] = date.today().strftime('%Y-%m-%d')
            elif value == '[NOT_FOUND]':
                render_params[key] = None
            else:
                match = re.match(r'\[DEFAULT_(\w+)\]', value)
                if match:
                    render_params[key] = match.group(1)

    try:
        template = Template(sql_template)
        return template.render(render_params)
    except Exception as e:
        return f"Error rendering Jinja2 template: {e}"

def get_report_structure_with_llm(user_query, all_recipes, mandatory_recipes=None):
    """Generate a report structure and extract parameters using the LLM."""
    try:
        with open("config.yaml", "r") as f:
            config = yaml.safe_load(f)
            api_key = config.get("api_keys", {}).get("gemini_api_key")

        if not api_key or api_key == "YOUR_GEMINI_API_KEY_HERE":
            st.error("Gemini API key is not configured. Please set it in `config.yaml`.")
            return None

        genai.configure(api_key=api_key)
        model = genai.GenerativeModel('gemini-2.5-flash')

        recipe_details = []
        for r in all_recipes:
            param_info = ", ".join([p['name'] for p in r.get('parameters', [])])
            recipe_details.append(
                f"- Recipe Name: {r.get('name')}\n  Description: {r.get('description')}\n  Category: {r.get('category')}\n  Parameters: [{param_info}]"
            )
        recipe_info_for_prompt = "\n".join(recipe_details)

        mandatory_recipes_prompt_part = ""
        if mandatory_recipes:
            mandatory_recipes_list = "\n".join([f"- {r}" for r in mandatory_recipes])
            mandatory_recipes_prompt_part = f"""
        IMPORTANT: The user has explicitly requested that the following recipes MUST be included in the report. Please build your narrative and report structure around them, while also selecting other relevant recipes to complete the story.
        ---
        MANDATORY RECIPES:
        {mandatory_recipes_list}
        ---
        """

        prompt = f"""You are a seasoned consultant for pharmaceutical companies, specializing in clinical data analysis and market strategy. Your task is to create a comprehensive report outline based on a user's request, tailored for a pharmaceutical company's drug development pipeline (e.g., market analysis, patient segmentation, clinical trial feasibility).

        {mandatory_recipes_prompt_part}

        IMPORTANT CONTEXT: The data must be filtered by the disease NAME (e.g., 'ê³ í˜ˆì••') in the 'res_disease_name' column, NOT by disease code. The queries will be run on a Databricks environment.

        Based on the user's query: '{user_query}'

        And the following available analysis recipes:
        ---
        {recipe_info_for_prompt}
        ---

        Perform the following tasks:
        1.  **Analyze User Intent:** Determine if the user wants a "Feasibility Report" for clinical trial recruitment or a "Market Landscape Report" for a drug pipeline.
        2.  **Create a Narrative:** Based on the intent, devise a logical narrative for the strategic report.
        3.  **Select Recipes:** Choose a sequence of 3 to 5 recipes that best fit this narrative. If mandatory recipes are provided, you must use them.
        4.  **Extract Parameters:** For each recipe, extract parameters from the user's query. Use placeholders like '[NOT_FOUND]', '[DEFAULT_3_YEARS_AGO]', '[CURRENT_DATE]', or '[DEFAULT_50]' if a value isn't present.
        5.  **Generate Report Components:** Write a professional report title, a concise executive summary explaining the report's purpose, a table of contents, and a 'rationale' for each page explaining why that analysis is important for the strategic goal.

        Your output MUST be a single JSON object. Here are two examples of the expected output structure based on the user's intent.

        ---
        **EXAMPLE 1: Feasibility Report**
        - User Query: "ì²œì‹ì„ ë™ë°˜í•œ ë‹¤ë…„ì„± ì•Œë ˆë¥´ê¸° ë¹„ì—¼ í™˜ì ëŒ€ìƒ DW1807 3ìƒ ì„ìƒì‹œí—˜ í™˜ì ëª¨ì§‘ íƒ€ë‹¹ì„± ë¶„ì„"
        - Your JSON Output:
        ```json
        {{
            "report_title": "DW1807 ì„ìƒì‹œí—˜ í™˜ì ëª¨ì§‘ íƒ€ë‹¹ì„± ë¶„ì„",
            "executive_summary": "ë³¸ ë³´ê³ ì„œëŠ” 'ì²œì‹ì„ ë™ë°˜í•œ ë‹¤ë…„ì„± ì•Œë ˆë¥´ê¸° ë¹„ì—¼' í™˜ì ëŒ€ìƒ DW1807 3ìƒ ì„ìƒì‹œí—˜ì˜ í™˜ì ëª¨ì§‘ íƒ€ë‹¹ì„±ì„ ë¶„ì„í•©ë‹ˆë‹¤. ëª©í‘œ ëª¨ì§‘ ì¸ì› 200ëª…ì— ëŒ€í•´, í˜„ì¬ ë³´ìœ í•œ RWD ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì˜ˆìƒ ëª¨ì§‘ ì„±ê³µë¥  ë° ì†Œìš” ê¸°ê°„ì„ ì˜ˆì¸¡í•˜ì—¬ ì„ìƒì‹œí—˜ì˜ ì„±ê³µ ê°€ëŠ¥ì„±ì„ í‰ê°€í•˜ëŠ” ê²ƒì„ ëª©ì ìœ¼ë¡œ í•©ë‹ˆë‹¤.",
            "table_of_contents": [
                "1. ëª¨ì§‘ ì„±ê³µë¥  ë° ì†Œìš” ê¸°ê°„ ì˜ˆì¸¡",
                "2. í™˜ìêµ° ìƒì„¸ í”„ë¡œíŒŒì¼ ë¶„ì„",
                "3. ì£¼ìš” ë™ë°˜ ì§ˆí™˜ ë¶„ì„",
                "4. ê²½ìŸ ë° ê¸°ì¡´ ì²˜ë°© ì•½ë¬¼ í˜„í™©"
            ],
            "pages": [
                {{
                    "title": "1. ëª¨ì§‘ ì„±ê³µë¥  ë° ì†Œìš” ê¸°ê°„ ì˜ˆì¸¡",
                    "rationale": "ì „ì²´ í™˜ì í’€ì—ì„œë¶€í„° ì£¼ìš” í¬í•¨/ì œì™¸ ê¸°ì¤€ì„ ì ìš©í•˜ì—¬ ìµœì¢… ëª¨ì§‘ ê°€ëŠ¥í•œ í™˜ì ìˆ˜ë¥¼ ì˜ˆì¸¡í•˜ê³ , ì´ë¥¼ í†µí•´ ëª©í‘œ ì¸ì› ë‹¬ì„± ê°€ëŠ¥ì„±ê³¼ ì˜ˆìƒ ì†Œìš” ê¸°ê°„ì„ ì‚°ì¶œí•©ë‹ˆë‹¤.",
                    "recipe_name": "analyze_recruitment_feasibility",
                    "parameters": {{"disease_name_keyword": "ì•Œë ˆë¥´ê¸° ë¹„ì—¼", "min_age": 19, "max_age": 75, "min_visits": 1, "target_enrollment": 200}}
                }},
                {{
                    "title": "2. í™˜ìêµ° ìƒì„¸ í”„ë¡œíŒŒì¼ ë¶„ì„",
                    "rationale": "ëª¨ì§‘ ëŒ€ìƒ í™˜ìêµ°ì˜ ì¸êµ¬í†µê³„í•™ì  íŠ¹ì„±(ì„±ë³„, ì—°ë ¹) ë° ì§€ì—­ì  ë¶„í¬ë¥¼ íŒŒì•…í•˜ì—¬, ë¦¬í¬ë£¨íŒ… ì „ëµ ìˆ˜ë¦½ ì‹œ íƒ€ê²Ÿ ëŒ€ìƒì„ ëª…í™•íˆ í•©ë‹ˆë‹¤.",
                    "recipe_name": "get_demographic_distribution_by_disease",
                    "parameters": {{"disease_name_keyword": "ì•Œë ˆë¥´ê¸° ë¹„ì—¼", "start_date": "[DEFAULT_3_YEARS_AGO]", "end_date": "[CURRENT_DATE]"}}
                }},
                {{
                    "title": "3. ì£¼ìš” ë™ë°˜ ì§ˆí™˜ ë¶„ì„",
                    "rationale": "ëŒ€ìƒ í™˜ìêµ°ì´ ë³´ìœ í•œ ì£¼ìš” ë™ë°˜ ì§ˆí™˜ì„ íŒŒì•…í•˜ì—¬, ì„ìƒì‹œí—˜ ì§„í–‰ ì¤‘ ë°œìƒí•  ìˆ˜ ìˆëŠ” ì ì¬ì  ë¦¬ìŠ¤í¬ë¥¼ ê´€ë¦¬í•˜ê³ , ë³µí•©ì ì¸ í™˜ì íŠ¹ì„±ì„ ì´í•´í•©ë‹ˆë‹¤.",
                    "recipe_name": "get_top_comorbidities_for_cohort",
                    "parameters": {{"disease_name_keyword": "ì•Œë ˆë¥´ê¸° ë¹„ì—¼", "start_date": "[DEFAULT_3_YEARS_AGO]", "end_date": "[CURRENT_DATE]", "top_n": 10}}
                }},
                {{
                    "title": "4. ê²½ìŸ ë° ê¸°ì¡´ ì²˜ë°© ì•½ë¬¼ í˜„í™©",
                    "rationale": "í˜„ì¬ ì‹œì¥ì—ì„œ ì²˜ë°©ë˜ê³  ìˆëŠ” ì£¼ìš” ì•½ë¬¼ë“¤ì„ íŒŒì•…í•˜ì—¬, ëŒ€ìƒ í™˜ìêµ°ì˜ ê¸°ì¡´ ì¹˜ë£Œ íŒ¨í„´ì„ ì´í•´í•˜ê³  ì„ìƒì‹œí—˜ ì„¤ê³„ ì‹œ ëŒ€ì¡°êµ° ì„¤ì • ë° ì‹œì¥ ì§„ì… ì „ëµì— í™œìš©í•©ë‹ˆë‹¤.",
                    "recipe_name": "get_top_prescribed_ingredients_by_disease",
                    "parameters": {{"disease_name_keyword": "ì•Œë ˆë¥´ê¸° ë¹„ì—¼", "start_date": "[DEFAULT_3_YEARS_AGO]", "end_date": "[CURRENT_DATE]", "top_n": 10}}
                }}
            ]
        }}
        ```
        ---
        **EXAMPLE 2: Market Landscape Report**
        - User Query: "ì›í˜•íƒˆëª¨ì¦ ì‹ ì•½ ì‹œì¥ì„± ë¶„ì„"
        - Your JSON Output:
        ```json
        {{
            "report_title": "ì›í˜•íƒˆëª¨ì¦ ì‹œì¥ ë¶„ì„ ë° í™˜ì í”„ë¡œíŒŒì¼ë§",
            "executive_summary": "ë³¸ ë³´ê³ ì„œëŠ” ì‹ ê·œ ì›í˜•íƒˆëª¨ì¦ ì¹˜ë£Œì œ ê°œë°œì„ ìœ„í•œ ì‹œì¥ì„± ë¶„ì„ì„ ëª©ì ìœ¼ë¡œ í•©ë‹ˆë‹¤. RWDë¥¼ ê¸°ë°˜ìœ¼ë¡œ êµ­ë‚´ ì›í˜•íƒˆëª¨ì¦ ì‹œì¥ì˜ ê·œëª¨ë¥¼ ì¶”ì •í•˜ê³ , í™˜ì íŠ¹ì„± ë° ì£¼ìš” ì˜ë£Œ ì´ìš© íŒ¨í„´ì„ ë¶„ì„í•˜ì—¬, ì„±ê³µì ì¸ ì‹ ì•½ ê°œë°œ ë° ì‹œì¥ ì§„ì… ì „ëµ ìˆ˜ë¦½ì„ ìœ„í•œ í•µì‹¬ ì¸ì‚¬ì´íŠ¸ë¥¼ ì œê³µí•©ë‹ˆë‹¤.",
            "table_of_contents": [
                "1. ì „ì²´ ì‹œì¥ ê·œëª¨ ë¶„ì„",
                "2. í™˜ì ì¸êµ¬í†µê³„í•™ì  íŠ¹ì„±",
                "3. ì£¼ìš” ì˜ë£Œ ì´ìš© íŒ¨í„´ (ë³‘ì› ë“±ê¸‰ë³„)",
                "4. ì£¼ìš” ì²˜ë°© ì•½ë¬¼ ë¶„ì„"
            ],
            "pages": [
                {{
                    "title": "1. ì „ì²´ ì‹œì¥ ê·œëª¨ ë¶„ì„",
                    "rationale": "êµ­ë‚´ ì›í˜•íƒˆëª¨ì¦ í™˜ìì˜ ì „ì²´ ìˆ˜ë¥¼ íŒŒì•…í•˜ì—¬ ì‹œì¥ì˜ ë§¤ë ¥ë„ë¥¼ í‰ê°€í•˜ê³ , ì ì¬ì  ì‹œì¥ ê·œëª¨ë¥¼ ì˜ˆì¸¡í•©ë‹ˆë‹¤.",
                    "recipe_name": "get_patient_count_by_disease_keyword",
                    "parameters": {{"disease_keyword": "ì›í˜•íƒˆëª¨ì¦"}}
                }},
                {{
                    "title": "2. í™˜ì ì¸êµ¬í†µê³„í•™ì  íŠ¹ì„±",
                    "rationale": "ì£¼ìš” í™˜ìêµ°ì˜ ì„±ë³„ ë° ì—°ë ¹ëŒ€ ë¶„í¬ë¥¼ ë¶„ì„í•˜ì—¬, ë§ˆì¼€íŒ… ë° ê°œë°œ ì „ëµ ìˆ˜ë¦½ ì‹œ í•µì‹¬ íƒ€ê²Ÿì´ ë  ì¸êµ¬í†µê³„í•™ì  ì„¸ê·¸ë¨¼íŠ¸ë¥¼ ì‹ë³„í•©ë‹ˆë‹¤.",
                    "recipe_name": "get_demographic_distribution_by_disease",
                    "parameters": {{"disease_name_keyword": "ì›í˜•íƒˆëª¨ì¦", "start_date": "[DEFAULT_3_YEARS_AGO]", "end_date": "[CURRENT_DATE]"}}
                }},
                {{
                    "title": "3. ì£¼ìš” ì˜ë£Œ ì´ìš© íŒ¨í„´ (ë³‘ì› ë“±ê¸‰ë³„)",
                    "rationale": "í™˜ìë“¤ì´ ì£¼ë¡œ ì´ìš©í•˜ëŠ” ë³‘ì› ë“±ê¸‰(1, 2, 3ì°¨)ì„ ë¶„ì„í•˜ì—¬, ì œí’ˆ ì¶œì‹œ í›„ ì˜ì—… ë° ë§ˆì¼€íŒ… ì±„ë„ ì „ëµì„ ìˆ˜ë¦½í•˜ëŠ” ë° í™œìš©í•©ë‹ˆë‹¤.",
                    "recipe_name": "analyze_visits_by_hospital_tier",
                    "parameters": {{"disease_keyword": "ì›í˜•íƒˆëª¨ì¦"}}
                }},
                {{
                    "title": "4. ì£¼ìš” ì²˜ë°© ì•½ë¬¼ ë¶„ì„",
                    "rationale": "í˜„ì¬ ì‹œì¥ì˜ í‘œì¤€ ì¹˜ë£Œ(Standard of Care)ì™€ ì£¼ìš” ê²½ìŸ ì•½ë¬¼ì„ íŒŒì•…í•˜ì—¬, ê°œë°œ ì¤‘ì¸ ì‹ ì•½ì˜ ì‹œì¥ ë‚´ í¬ì§€ì…”ë‹ ë° ì°¨ë³„í™” ì „ëµì„ ìˆ˜ë¦½í•©ë‹ˆë‹¤.",
                    "recipe_name": "get_top_prescribed_ingredients_by_disease",
                    "parameters": {{"disease_name_keyword": "ì›í˜•íƒˆëª¨ì¦", "start_date": "[DEFAULT_3_YEARS_AGO]", "end_date": "[CURRENT_DATE]", "top_n": 10}}
                }}
            ]
        }}
        ```
        ---

        Ensure the recipe names and parameter names in your output *exactly* match the provided list. Now, generate the JSON for the user's query: '{user_query}'.
        """

        response = model.generate_content(prompt)
        cleaned_response_text = response.text.strip().replace("```json", "").replace("```", "")
        return json.loads(cleaned_response_text)

    except Exception as e:
        st.error(f"An error occurred while communicating with the LLM: {e}")
        return None

def robust_csv_parser(data_input):
    """Parses CSV-like data from a string or uploaded file using pandas' auto-detection."""
    if hasattr(data_input, 'getvalue'):
        text_data = data_input.getvalue().decode('utf-8')
    else:
        text_data = str(data_input)
    
    csv_file = io.StringIO(text_data)
    # Use sep=None and engine='python' to auto-detect separators
    df = pd.read_csv(csv_file, sep=None, engine='python')
    return df

# --- Main App Logic ---

st.set_page_config(page_title="Clinical Report Query Generator", layout="wide")
st.title("ğŸ“‘ Clinical Report Query Generator")
st.caption("AI-powered SQL generator for clinical data analysis...")

if 'report_structure' not in st.session_state:
    st.session_state.report_structure = None

with st.spinner("Loading recipes and data dictionary..."):
    all_recipes = load_recipes()
    recipe_dict = {recipe['name']: recipe for recipe in all_recipes if recipe}
    data_dictionary = load_data_dictionary()

if not all_recipes:
    st.stop()

# --- Sidebar ---
st.sidebar.header("User Input")
user_query = st.sidebar.text_area(
    "ë¶„ì„ ë¦¬í¬íŠ¸ì˜ ì£¼ì œë‚˜ ì›í•˜ëŠ” ë¶„ì„ íë¦„ì„ ììœ ë¡­ê²Œ ì…ë ¥í•˜ì„¸ìš”. (ì˜ˆ: \"20ëŒ€ ì—¬ì„± ë¹„ë§Œ í™˜ì í”„ë¡œíŒŒì¼ë§\" ë˜ëŠ” \"ì‹œì¥ ê·œëª¨ë¥¼ ë¨¼ì € ë³´ê³ , ë‹¤ìŒìœ¼ë¡œ ì£¼ìš” ì²˜ë°© ì•½ë¬¼ì„ ë¶„ì„í•˜ëŠ” ë³´ê³ ì„œ\")",
    height=100,
    key="user_query_input"
)

# --- New UI for mandatory recipes ---
st.sidebar.subheader("í•„ìˆ˜ í¬í•¨ ë ˆì‹œí”¼ ì„ íƒ (ì˜µì…˜)")
# Group full recipe objects by category
categorized_recipes = {}
for r in all_recipes:
    cat = r.get('category', 'Uncategorized')
    if cat not in categorized_recipes:
        categorized_recipes[cat] = []
    categorized_recipes[cat].append(r)

selected_recipes = []
# Sort categories for consistent order
for category in sorted(categorized_recipes.keys()):
    with st.sidebar.expander(f"ì¹´í…Œê³ ë¦¬: {category}", expanded=False):
        # Sort recipes within the category by name
        for recipe in sorted(categorized_recipes[category], key=lambda x: x['name']):
            recipe_name = recipe['name']
            recipe_desc = recipe.get('description', 'No description available.')
            # Use checkbox with description as label
            if st.checkbox(f"{recipe_name}: {recipe_desc}", key=f"checkbox_{recipe_name}"):
                selected_recipes.append(recipe_name)
# --- End of New UI ---

def clear_report_state():
    st.session_state.report_structure = None
    for key in list(st.session_state.keys()):
        if key.startswith('dataframe_') or key.startswith('csv_input_') or key.startswith('uploader_'):
            del st.session_state[key]

if st.sidebar.button("Generate Report", type="primary"):
    clear_report_state()
    if user_query:
        with st.spinner("AI is generating the report..."):
            # Pass selected_recipes to the LLM function
            st.session_state.report_structure = get_report_structure_with_llm(user_query, all_recipes, selected_recipes)
    else:
        st.warning("Please enter a topic for the report.")

if st.sidebar.button("Clear Report"):
    clear_report_state()

st.sidebar.divider()
if st.sidebar.toggle("Show Data Dictionary", False):
    st.subheader("Data Dictionary")
    if data_dictionary is not None:
        st.dataframe(data_dictionary)
    else:
        st.warning("Data dictionary file (`notion_columns_improved.csv`) not found.")

# --- Main Content ---
# Create main tabs
tab_names = ["ğŸ“Š General Report", "ğŸ¥ Clinical Trial Screening"]
if not CLINICAL_TRIAL_AVAILABLE:
    tab_names = ["ğŸ“Š General Report"]

main_tabs = st.tabs(tab_names)

# Tab 1: General Report (existing functionality)
with main_tabs[0]:
    if st.session_state.report_structure:
        report_structure = st.session_state.report_structure
        if "report_title" in report_structure and "pages" in report_structure:
            st.header(report_structure["report_title"])

            # Display Executive Summary and ToC
            if "executive_summary" in report_structure:
                st.subheader("Executive Summary")
                st.markdown(report_structure["executive_summary"])

            if "table_of_contents" in report_structure:
                st.subheader("Table of Contents")
                for item in report_structure["table_of_contents"]:
                    st.markdown(f"- {item}")

            st.divider()

            tab_titles = [page.get("title", f"Page {i+1}") for i, page in enumerate(report_structure["pages"])]
            tabs = st.tabs(tab_titles)

            for i, page in enumerate(report_structure["pages"]):
                with tabs[i]:
                    recipe_name = page.get("recipe_name")
                    recipe = recipe_dict.get(recipe_name)
                    llm_params = page.get("parameters", {})

                    if not recipe:
                        st.error(f"LLM recommended recipe '{recipe_name}', but it was not found.")
                        continue

                    # Display the rationale
                    if "rationale" in page:
                        st.info(f"**Rationale:** {page['rationale']}")

                    st.subheader(f"Recipe: `{recipe_name}`")
                    st.markdown(f"**Description:** {recipe.get('description', 'N/A')}")
                    st.json(llm_params)

                    st.subheader("Final SQL Query")
                    sql_template = get_sql_from_recipe(recipe)
                    final_sql = fill_sql_parameters(sql_template, llm_params)
                    st.code(final_sql, language="sql")

                    st.divider()
                    st.subheader("ğŸ“Š Generate Visualization")
                    df_key = f"dataframe_{i}"

                    viz_tab1, viz_tab2 = st.tabs(["Paste Text", "Upload File"])

                    with viz_tab1:
                        csv_input_key = f"csv_input_{i}"
                        st.text_area("Paste CSV data...", height=150, key=csv_input_key)
                        if st.button("Generate from Text", key=f"text_button_{i}"):
                            csv_text = st.session_state.get(csv_input_key, "")
                            if csv_text:
                                try:
                                    df = robust_csv_parser(csv_text)
                                    st.session_state[df_key] = df
                                except Exception as e:
                                    st.error(f"Failed to parse CSV from text: {e}")
                                    if df_key in st.session_state: del st.session_state[df_key]
                            else:
                                st.warning("Please paste CSV data first.")

                    with viz_tab2:
                        upload_key = f"uploader_{i}"
                        uploaded_file = st.file_uploader("Upload CSV file...", type=["csv", "txt"], key=upload_key)
                        if uploaded_file is not None:
                            try:
                                df = robust_csv_parser(uploaded_file)
                                st.session_state[df_key] = df
                            except Exception as e:
                                st.error(f"Failed to parse CSV from file: {e}")
                                if df_key in st.session_state: del st.session_state[df_key]

                    if df_key in st.session_state:
                        df = st.session_state[df_key]
                        viz_info = recipe.get("visualization")

                        st.write("**Chart:**")
                        if viz_info:
                            chart_type = viz_info.get("chart_type")

                            try:
                                if chart_type == "bar_chart":
                                    x_col = viz_info.get("x_column")
                                    y_col = viz_info.get("y_column")
                                    st.bar_chart(df.set_index(x_col)[y_col])

                                elif chart_type == "metric":
                                    # For single-row dataframes, display each column as a metric
                                    if not df.empty:
                                        cols = st.columns(len(df.columns))
                                        for j, col_name in enumerate(df.columns):
                                            cols[j].metric(label=col_name, value=df.iloc[0][col_name])
                                    else:
                                        st.warning("Data is empty, cannot display metrics.")

                                else: # Default to table
                                    st.write("**Parsed Data Table:**")
                                    st.dataframe(df)

                            except Exception as e:
                                st.error(f"Failed to generate chart: {e}")
                                st.write("Displaying raw data instead:")
                                st.dataframe(df)
                        else:
                            st.write("No visualization info in recipe. Displaying raw data table.")
                            st.dataframe(df)

        else:
            st.error("Failed to generate a valid report structure from the LLM.")
    else:
        st.info("Enter a topic in the sidebar and click 'Generate Report' to begin.")

# Tab 2: Clinical Trial Screening (new functionality)
if CLINICAL_TRIAL_AVAILABLE and len(main_tabs) > 1:
    with main_tabs[1]:
        st.header("ğŸ¥ Clinical Trial Screening Automation")
        st.markdown("ìì—°ì–´ ì„ìƒì‹œí—˜ ì¡°ê±´ì„ ì…ë ¥í•˜ë©´ ìë™ìœ¼ë¡œ ì í•©í•œ SQL ì¿¼ë¦¬ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.")

        # Sub-tabs for different functionalities
        trial_sub_tabs = st.tabs(["ğŸš€ ìŠ¤í¬ë¦¬ë‹ ì‹¤í–‰", "ğŸ” ê¸°ì¤€ ë¶„ì„"])

        # Tab 1: Screening Execution (existing functionality)
        with trial_sub_tabs[0]:
            st.subheader("ì„ìƒì‹œí—˜ ì¡°ê±´ ì…ë ¥")
            col1, col2 = st.columns(2)
            with col1:
                trial_name = st.text_input(
                    "ì„ìƒì‹œí—˜ëª…",
                    value="ê³ í˜ˆì•• ì‹ ì•½ ì„ìƒì‹œí—˜",
                    help="ë¶„ì„í•  ì„ìƒì‹œí—˜ì˜ ì´ë¦„ì„ ì…ë ¥í•˜ì„¸ìš”",
                    key="screening_trial_name"
                )
                inclusion_criteria = st.text_area(
                    "í¬í•¨ ê¸°ì¤€ (Inclusion Criteria)",
                    value="""ë§Œ 19ì„¸ ì´ìƒ ì„±ì¸ ë‚¨ë…€
Visit 1 ê¸°ì¤€ í‰ê·  ì¢Œìœ„ ìˆ˜ì¶•ê¸° í˜ˆì••ì´ 140-180 mmHg ë²”ìœ„
í•­ê³ í˜ˆì••ì œ ë³µìš© ì¤‘ì¸ ê²½ìš°, ì‹œí—˜ìì˜ íŒë‹¨ì— ë”°ë¼ ì¹˜ë£Œ ì¤‘ë‹¨ì´ ê°€ëŠ¥í•œ í™˜ì
ì—¬ì„± ëŒ€ìƒìì˜ ê²½ìš° í”¼ì„ ì¡°ê±´ ì¶©ì¡±
ì‹œí—˜ ëª©ì Â·ë‚´ìš© ì„¤ëª…ì„ ë“£ê³  ìë°œì  ì„œë©´ ë™ì˜ë¥¼ í•œ í™˜ì""",
                    height=150,
                    help="í™˜ìê°€ ì„ìƒì‹œí—˜ì— ì°¸ì—¬í•˜ê¸° ìœ„í•œ í¬í•¨ ì¡°ê±´ë“¤ì„ ì…ë ¥í•˜ì„¸ìš”",
                    key="screening_inclusion_criteria"
                )
            with col2:
                exclusion_criteria = st.text_area(
                    "ì œì™¸ ê¸°ì¤€ (Exclusion Criteria)",
                    value="""Visit 1 ë˜ëŠ” Visit 2ì—ì„œ MSSBP â‰¥ 180 mmHg ë˜ëŠ” MSDBP â‰¥ 110 mmHg
ìµœê·¼ 5ë…„ ì´ë‚´ ì•…ì„±ì¢…ì–‘ ë³‘ë ¥
ìµœê·¼ 12ê°œì›” ì´ë‚´ ì‹¬ê·¼ê²½ìƒ‰ ë˜ëŠ” ë‡Œì¡¸ì¤‘ ë³‘ë ¥
ì„ì‹ ë¶€ ë˜ëŠ” ìˆ˜ìœ ë¶€
ì•½ë¬¼ ë˜ëŠ” ì•Œì½”ì˜¬ ë‚¨ìš© ë³‘ë ¥
ì‹œí—˜ì•½ ì„±ë¶„ì— ê³¼ë¯¼ì¦ ê¸°ì™•ë ¥""",
                    height=150,
                    help="ì„ìƒì‹œí—˜ì—ì„œ ì œì™¸ë˜ì–´ì•¼ í•  ì¡°ê±´ë“¤ì„ ì…ë ¥í•˜ì„¸ìš”",
                    key="screening_exclusion_criteria"
                )

                # Execution options
                dry_run = st.checkbox(
                    "Dry Run ëª¨ë“œ (SQL ìƒì„±ë§Œ, ì‹¤í–‰ ì•ˆí•¨)",
                    value=True,
                    help="ì²´í¬í•˜ë©´ SQL ì¿¼ë¦¬ë§Œ ìƒì„±í•˜ê³  ì‹¤ì œ ì‹¤í–‰ì€ í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤",
                    key="screening_dry_run"
                )
                comprehensive_analysis = st.checkbox(
                    "ì¢…í•© ë¶„ì„ ëª¨ë“œ (ê¸°ë³¸ ìŠ¤í¬ë¦¬ë‹ + LLM ê¸°ë°˜ ì¶”ê°€ ë¶„ì„)",
                    value=False,
                    help="ì²´í¬í•˜ë©´ ê¸°ë³¸ ìŠ¤í¬ë¦¬ë‹ í›„ LLMì„ í™œìš©í•œ ì¶”ê°€ ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤",
                    key="screening_comprehensive"
                )

            # Initialize clinical trial agent
            if 'clinical_agent' not in st.session_state:
                with st.spinner("ì„ìƒì‹œí—˜ ì—ì´ì „íŠ¸ ì´ˆê¸°í™” ì¤‘..."):
                    try:
                        st.session_state.clinical_agent = ClinicalTrialAgent()
                        st.success("âœ… ì„ìƒì‹œí—˜ ì—ì´ì „íŠ¸ ì¤€ë¹„ ì™„ë£Œ!")
                    except Exception as e:
                        st.error(f"ì„ìƒì‹œí—˜ ì—ì´ì „íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                        st.stop()

        # Tab 2: Criteria Analysis (new functionality with file/text input)
        with trial_sub_tabs[1]:
            st.subheader("ğŸ” ê¸°ì¤€ ì¿¼ë¦¬ ê²€ì¦ ê°€ëŠ¥ì„± ë¶„ì„")
            st.markdown("ì„ìƒì‹œí—˜ ê¸°ì¤€ í…ìŠ¤íŠ¸ ì „ì²´ë¥¼ ì…ë ¥í•˜ì—¬ ë°ì´í„°ë¸Œë¦­ìŠ¤ë¡œ ê²€ì¦ ê°€ëŠ¥í•œì§€ ë¶„ì„í•©ë‹ˆë‹¤.")

            # Input method selection
            input_method = st.radio(
                "ì…ë ¥ ë°©ë²• ì„ íƒ:",
                ["ğŸ“ ì§ì ‘ í…ìŠ¤íŠ¸ ì…ë ¥", "ğŸ“ íŒŒì¼ ì—…ë¡œë“œ"],
                key="criteria_input_method"
            )
            if trial_name and inclusion_criteria and exclusion_criteria:
                spinner_text = f"ì„ìƒì‹œí—˜ ì¡°ê±´ ë¶„ì„ ë° ì¿¼ë¦¬ ìƒì„± ì¤‘... ({analysis_type})"
                with st.spinner(spinner_text):
                    try:
                        if comprehensive_analysis:
                            result = st.session_state.clinical_agent.run_comprehensive_clinical_analysis(
                                trial_name=trial_name,
                                inclusion_criteria=inclusion_criteria,
                                exclusion_criteria=exclusion_criteria,
                                dry_run=dry_run
                            )
                        else:
                            result = st.session_state.clinical_agent.run_clinical_trial_screening(
                                trial_name=trial_name,
                                inclusion_criteria=inclusion_criteria,
                                exclusion_criteria=exclusion_criteria,
                                dry_run=dry_run
                            )

                        st.success(f"âœ… ì„ìƒì‹œí—˜ {analysis_type} ì™„ë£Œ!")

                        # Handle comprehensive analysis vs basic screening results
                        if comprehensive_analysis:
                            # For comprehensive analysis
                            screening_result = result.get('screening_result', {})
                            execution_results = result.get('all_executed_recipes', [])
                            screening_success_rate = result.get('overall_success_rate', 0.0)

                            # Display LLM insights if available
                            if 'llm_insights' in result:
                                st.subheader("ğŸ¤– LLM ë¶„ì„ ì¸ì‚¬ì´íŠ¸")
                                insights = result['llm_insights']

                                if insights.get('clinical_significance'):
                                    st.info(f"**ì„ìƒì  ì˜ë¯¸:** {insights['clinical_significance']}")

                                if insights.get('recommended_analyses'):
                                    st.write("**ê¶Œì¥ ì¶”ê°€ ë¶„ì„:**")
                                    for analysis in insights['recommended_analyses']:
                                        st.write(f"â€¢ {analysis}")

                                if insights.get('data_gaps'):
                                    st.warning("**ë°ì´í„° ë¶€ì¡± ì˜ì—­:**")
                                    for gap in insights['data_gaps']:
                                        st.write(f"â€¢ {gap}")

                                if insights.get('next_steps'):
                                    st.success(f"**ë‹¤ìŒ ë‹¨ê³„:** {insights['next_steps']}")

                                st.divider()
                        else:
                            # For basic screening
                            execution_results = result.get('execution_results', [])
                            screening_success_rate = result.get('success_rate', 0.0)

                        # Summary metrics
                        col1, col2, col3 = st.columns(3)
                        with col1:
                            st.metric("ì„±ê³µë¥ ", f"{screening_success_rate:.1%}")
                        with col2:
                            st.metric("ì‹¤í–‰ëœ ë ˆì‹œí”¼", f"{len(execution_results)}ê°œ")
                        with col3:
                            success_count = sum(1 for r in execution_results if r.success)
                            st.metric("ì„±ê³µí•œ ë ˆì‹œí”¼", f"{success_count}ê°œ")

                        st.divider()

                        # Detailed results
                        result_title = "ğŸ“‹ ì¢…í•© ë¶„ì„ ì‹¤í–‰ ê²°ê³¼" if comprehensive_analysis else "ğŸ“‹ ê¸°ë³¸ ìŠ¤í¬ë¦¬ë‹ ì‹¤í–‰ ê²°ê³¼"
                        st.subheader(result_title)

                        for i, exec_result in enumerate(execution_results, 1):
                            with st.expander(f"{i}. {exec_result.recipe_name} {'âœ…' if exec_result.success else 'âŒ'}", expanded=True):
                                if exec_result.success:
                                    st.success("SQL ìƒì„± ì„±ê³µ")

                                    # SQL ì¿¼ë¦¬ í‘œì‹œ (ì „ì²´)
                                    if hasattr(exec_result, 'generated_sql') and exec_result.generated_sql:
                                        st.subheader("ğŸ“ ìƒì„±ëœ SQL ì¿¼ë¦¬")

                                        # SQL ê¸¸ì´ ì •ë³´
                                        sql_length = len(exec_result.generated_sql)
                                        st.info(f"SQL ê¸¸ì´: {sql_length:,} ê¸€ì")

                                        # ì „ì²´ SQL í‘œì‹œ (ìŠ¤í¬ë¡¤ ê°€ëŠ¥)
                                        st.code(exec_result.generated_sql, language="sql", line_numbers=True)

                                        # ë³µì‚¬ìš© í…ìŠ¤íŠ¸ ì˜ì—­ (ì„ íƒì‚¬í•­)
                                        with st.expander("ğŸ“‹ ë³µì‚¬ìš© SQL (ì „ì²´ ì„ íƒ ê°€ëŠ¥)", expanded=False):
                                            st.text_area(
                                                "SQL ì¿¼ë¦¬ (ì „ì²´ ì„ íƒ í›„ ë³µì‚¬í•˜ì„¸ìš”)",
                                                value=exec_result.generated_sql,
                                                height=200,
                                                key=f"sql_copy_{i}",
                                                help="ì´ ì˜ì—­ì—ì„œ ì „ì²´ ì„ íƒ(Ctrl+A)í›„ ë³µì‚¬(Ctrl+C)í•˜ì„¸ìš”"
                                            )

                                    # íŒŒë¼ë¯¸í„° í‘œì‹œ
                                    if hasattr(exec_result, 'parameters') and exec_result.parameters:
                                        st.subheader("âš™ï¸ ì‚¬ìš©ëœ íŒŒë¼ë¯¸í„°")
                                        st.json(exec_result.parameters)

                                        # íŒŒë¼ë¯¸í„° ê°œìˆ˜ ì •ë³´
                                        param_count = len(exec_result.parameters)
                                        st.caption(f"ì´ {param_count}ê°œ íŒŒë¼ë¯¸í„° ì‚¬ìš©ë¨")

                                else:
                                    st.error(f"ì‹¤í–‰ ì‹¤íŒ¨: {exec_result.error_message}")

                        # Show analyzed criteria
                        if 'analyzed_criteria' in result:
                            st.subheader("ğŸ” ë¶„ì„ëœ ì„ìƒ ì¡°ê±´")

                            criteria = result['analyzed_criteria']

                            col1, col2 = st.columns(2)
                            with col1:
                                st.write("**í¬í•¨ ì¡°ê±´:**")
                                for criterion in criteria.get('inclusion', []):
                                    st.write(f"â€¢ [{criterion.criteria_type.value}] {criterion.description[:100]}...")

                            with col2:
                                st.write("**ì œì™¸ ì¡°ê±´:**")
                                for criterion in criteria.get('exclusion', []):
                                    st.write(f"â€¢ [{criterion.criteria_type.value}] {criterion.description[:100]}...")

                    except Exception as e:
                        st.error(f"ì„ìƒì‹œí—˜ ìŠ¤í¬ë¦¬ë‹ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                        st.exception(e)
            else:
                st.warning("ëª¨ë“  í•„ë“œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")

        # Information section
        st.divider()
        st.subheader("â„¹ï¸ ì‚¬ìš© ë°©ë²•")
        st.markdown("""
        1. **ì„ìƒì‹œí—˜ëª…**: ë¶„ì„í•  ì„ìƒì‹œí—˜ì˜ ì´ë¦„ì„ ì…ë ¥í•˜ì„¸ìš”
        2. **í¬í•¨ ê¸°ì¤€**: í™˜ìê°€ ì„ìƒì‹œí—˜ì— ì°¸ì—¬í•  ìˆ˜ ìˆëŠ” ì¡°ê±´ë“¤ì„ ìì—°ì–´ë¡œ ì…ë ¥í•˜ì„¸ìš”
        3. **ì œì™¸ ê¸°ì¤€**: ì„ìƒì‹œí—˜ì—ì„œ ì œì™¸ë˜ì–´ì•¼ í•  ì¡°ê±´ë“¤ì„ ìì—°ì–´ë¡œ ì…ë ¥í•˜ì„¸ìš”
        4. **ì‹¤í–‰**: ì‹œìŠ¤í…œì´ ìë™ìœ¼ë¡œ ì¡°ê±´ì„ ë¶„ì„í•˜ê³  ì í•©í•œ SQL ë ˆì‹œí”¼ë¥¼ ì„ íƒí•˜ì—¬ ì¿¼ë¦¬ë¥¼ ìƒì„±í•©ë‹ˆë‹¤

        **ì§€ì›í•˜ëŠ” ì¡°ê±´ ìœ í˜•:**
        - ì—°ë ¹ ì¡°ê±´ (ì˜ˆ: "ë§Œ 19ì„¸ ì´ìƒ", "18-65ì„¸")
        - ì„±ë³„ ì¡°ê±´ (ì˜ˆ: "ë‚¨ë…€", "ì—¬ì„±")
        - ì§ˆí™˜ ì¡°ê±´ (ì˜ˆ: "ê³ í˜ˆì••", "ë‹¹ë‡¨ë³‘")
        - ì•½ë¬¼ ì¡°ê±´ (ì˜ˆ: "í•­ê³ í˜ˆì••ì œ ë³µìš©", "ì¸ìŠë¦° ì¹˜ë£Œ")
        - **ìƒì²´ì§•í›„** (ì˜ˆ: "ìˆ˜ì¶•ê¸° í˜ˆì•• 140-180 mmHg", "BMI 25 ì´ìƒ", "ê³µë³µí˜ˆë‹¹ 126mg/dL ì´ìƒ")
        - ì„ì‹  ê´€ë ¨ (ì˜ˆ: "ì„ì‹ ë¶€", "ìˆ˜ìœ ë¶€")

        **ì‚¬ìš© ê°€ëŠ¥í•œ ìƒì²´ì§•í›„ ë°ì´í„°:**
        - í˜ˆì••, ê³µë³µí˜ˆë‹¹, BMI, ì½œë ˆìŠ¤í…Œë¡¤, ì¤‘ì„±ì§€ë°© ë“±
        """)

        # Tab 2: Criteria Analysis (new functionality with file/text input)
        with trial_sub_tabs[1]:
            st.subheader("ğŸ” ê¸°ì¤€ ì¿¼ë¦¬ ê²€ì¦ ê°€ëŠ¥ì„± ë¶„ì„")
            st.markdown("ì„ìƒì‹œí—˜ ê¸°ì¤€ í…ìŠ¤íŠ¸ ì „ì²´ë¥¼ ì…ë ¥í•˜ì—¬ ë°ì´í„°ë¸Œë¦­ìŠ¤ë¡œ ê²€ì¦ ê°€ëŠ¥í•œì§€ ë¶„ì„í•©ë‹ˆë‹¤.")

            # Input method selection
            input_method = st.radio(
                "ì…ë ¥ ë°©ë²• ì„ íƒ:",
                ["ğŸ“ ì§ì ‘ í…ìŠ¤íŠ¸ ì…ë ¥", "ğŸ“ íŒŒì¼ ì—…ë¡œë“œ"],
                key="criteria_input_method"
            )

            # Input section
            trial_name_analysis = None
            full_criteria_text = None

            if input_method == "ğŸ“ ì§ì ‘ í…ìŠ¤íŠ¸ ì…ë ¥":
                trial_name_analysis = st.text_input(
                    "ì„ìƒì‹œí—˜ëª…",
                    value="",
                    help="ë¶„ì„í•  ì„ìƒì‹œí—˜ì˜ ì´ë¦„ì„ ì…ë ¥í•˜ì„¸ìš”",
                    key="analysis_trial_name"
                )

                full_criteria_text = st.text_area(
                    "ì„ìƒì‹œí—˜ ê¸°ì¤€ ì „ì²´ í…ìŠ¤íŠ¸",
                    value="""ì„ìƒì‹œí—˜ëª…: ê³ í˜ˆì•• ì‹ ì•½ íš¨ëŠ¥ í‰ê°€ ì—°êµ¬

ì„ ì •ê¸°ì¤€:
1. ë§Œ 19ì„¸ ì´ìƒ 75ì„¸ ì´í•˜ì˜ ì„±ì¸ ë‚¨ë…€
2. ê³ í˜ˆì•• ì§„ë‹¨ì„ ë°›ê³  í˜„ì¬ í•­ê³ í˜ˆì••ì œë¥¼ ë³µìš© ì¤‘ì¸ í™˜ì
3. ìµœê·¼ 6ê°œì›” ì´ë‚´ í˜ˆì••ì´ 140/90 mmHg ì´ìƒìœ¼ë¡œ ì¸¡ì •ëœ í™˜ì
4. ì—°êµ¬ ì°¸ì—¬ì— ì„œë©´ ë™ì˜í•œ í™˜ì
5. ì—°êµ¬ ê¸°ê°„ ì¤‘ ì§€ì†ì ì¸ ì¶”ì ê´€ì°°ì´ ê°€ëŠ¥í•œ í™˜ì

ì œì™¸ê¸°ì¤€:
1. ì„ì‹  ë˜ëŠ” ìˆ˜ìœ  ì¤‘ì¸ ì—¬ì„±
2. ì‹¬ê°í•œ ê°„ê¸°ëŠ¥ ë˜ëŠ” ì‹ ê¸°ëŠ¥ ì¥ì• ê°€ ìˆëŠ” í™˜ì
3. ìµœê·¼ 3ê°œì›” ì´ë‚´ ì‹¬ê·¼ê²½ìƒ‰ì´ë‚˜ ë‡Œì¡¸ì¤‘ ë³‘ë ¥ì´ ìˆëŠ” í™˜ì
4. ì—°êµ¬ìê°€ ë¶€ì í•©í•˜ë‹¤ê³  íŒë‹¨í•˜ëŠ” í™˜ì
5. ë‹¤ë¥¸ ì„ìƒì‹œí—˜ì— ì°¸ì—¬ ì¤‘ì¸ í™˜ì""",
                    height=300,
                    help="ì„ìƒì‹œí—˜ ê¸°ì¤€ ì „ì²´ í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”. ì„ ì •ê¸°ì¤€ê³¼ ì œì™¸ê¸°ì¤€ì„ ëª¨ë‘ í¬í•¨í•´ì£¼ì„¸ìš”.",
                    key="analysis_full_text"
                )

            elif input_method == "ğŸ“ íŒŒì¼ ì—…ë¡œë“œ":
                uploaded_file = st.file_uploader(
                    "ì„ìƒì‹œí—˜ ê¸°ì¤€ íŒŒì¼ ì—…ë¡œë“œ",
                    type=["txt", "md", "docx"],
                    help="ì„ìƒì‹œí—˜ ê¸°ì¤€ì´ í¬í•¨ëœ í…ìŠ¤íŠ¸ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”",
                    key="criteria_file_upload"
                )

                if uploaded_file is not None:
                    try:
                        # Read file content
                        if uploaded_file.type == "text/plain":
                            full_criteria_text = str(uploaded_file.read(), "utf-8")
                        else:
                            st.warning("í˜„ì¬ëŠ” .txt íŒŒì¼ë§Œ ì§€ì›í•©ë‹ˆë‹¤.")

                        # Extract trial name from filename or first line
                        trial_name_analysis = uploaded_file.name.replace('.txt', '').replace('.md', '')

                        # Show preview
                        st.text_area(
                            "ì—…ë¡œë“œëœ íŒŒì¼ ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°:",
                            value=full_criteria_text[:1000] + "..." if len(full_criteria_text) > 1000 else full_criteria_text,
                            height=200,
                            disabled=True,
                            key="file_preview"
                        )

                    except Exception as e:
                        st.error(f"íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {e}")

            # Analysis section
            if trial_name_analysis and full_criteria_text:
                col_analyze1, col_analyze2 = st.columns(2)

                with col_analyze1:
                    if QUERYABLE_CRITERIA_AVAILABLE:
                        if st.button("ğŸ“Š ê¸°ì¤€ ë¶„ì„ ì‹¤í–‰", help="ì „ì²´ í…ìŠ¤íŠ¸ì—ì„œ ê¸°ì¤€ì„ ì¶”ì¶œí•˜ê³  ê²€ì¦ ê°€ëŠ¥ì„±ì„ ë¶„ì„í•©ë‹ˆë‹¤", key="criteria_analysis_button"):
                            with st.spinner("ì„ìƒì‹œí—˜ ê¸°ì¤€ ìë™ ì¶”ì¶œ ë° ë¶„ì„ ì¤‘..."):
                                try:
                                    # Initialize analyzer
                                    if 'criteria_analyzer' not in st.session_state:
                                        st.session_state.criteria_analyzer = QueryableCriteriaAnalyzer()

                                    # Parse the full text to extract inclusion/exclusion criteria
                                    inclusion_text, exclusion_text = parse_criteria_text(full_criteria_text)

                                    # Analyze criteria
                                    analysis_result = st.session_state.criteria_analyzer.analyze_trial_criteria(
                                        trial_name=trial_name_analysis,
                                        inclusion_criteria=inclusion_text,
                                        exclusion_criteria=exclusion_text
                                    )

                                    # Store result in session state
                                    st.session_state.criteria_analysis_result = analysis_result

                                    st.success("âœ… ê¸°ì¤€ ë¶„ì„ ì™„ë£Œ!")

                                except Exception as e:
                                    st.error(f"âŒ ê¸°ì¤€ ë¶„ì„ ì‹¤íŒ¨: {e}")
                                    st.exception(e)
                    else:
                        st.warning("QueryableCriteriaAnalyzerë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. GEMINI_API_KEYë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")

                with col_analyze2:
                    # Display analysis results if available
                    if hasattr(st.session_state, 'criteria_analysis_result'):
                        result = st.session_state.criteria_analysis_result

                        # Quick stats
                        total_criteria = result['total_criteria_count']
                        queryability_ratio = result['overall_queryability_ratio']

                        st.metric(
                            "ì¿¼ë¦¬ ê²€ì¦ ê°€ëŠ¥ë¥ ",
                            f"{queryability_ratio:.1%}",
                            f"{total_criteria}ê°œ ê¸°ì¤€ ì¤‘ {int(total_criteria * queryability_ratio)}ê°œ"
                        )

                        # Distribution
                        high_count = result['queryability_distribution']['HIGH']
                        medium_count = result['queryability_distribution']['MEDIUM']
                        low_count = result['queryability_distribution']['LOW']

                        st.write("**ê²€ì¦ ê°€ëŠ¥ì„± ë¶„í¬:**")
                        st.write(f"ğŸŸ¢ HIGH: {high_count}ê°œ")
                        st.write(f"ğŸŸ¡ MEDIUM: {medium_count}ê°œ")
                        st.write(f"ğŸ”´ LOW: {low_count}ê°œ")
            else:
                st.info("ì„ìƒì‹œí—˜ëª…ê³¼ ê¸°ì¤€ í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ê³  ë¶„ì„ì„ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")

            # Display detailed analysis results if available
            if hasattr(st.session_state, 'criteria_analysis_result'):
                st.divider()
                result = st.session_state.criteria_analysis_result

                # Show recommended recipes
                if result.get('recommended_recipes'):
                    st.subheader("ğŸ”§ ê¶Œì¥ ë ˆì‹œí”¼")
                    for recipe in result['recommended_recipes'][:10]:  # Show top 10
                        st.write(f"â€¢ {recipe}")

                # Show queryable criteria details
                st.subheader("ğŸ“‹ ìƒì„¸ ë¶„ì„ ê²°ê³¼")

                col1, col2 = st.columns(2)

                with col1:
                    st.write("**âœ… ê²€ì¦ ê°€ëŠ¥í•œ ê¸°ì¤€ë“¤:**")
                    queryable_criteria = [c for c in result['inclusion_analysis'] + result['exclusion_analysis']
                                        if c.overall_queryability.value in ['HIGH', 'MEDIUM']]

                    for i, criteria in enumerate(queryable_criteria[:5], 1):  # Show top 5
                        with st.expander(f"{i}. [{criteria.overall_queryability.value}] {criteria.original_text[:50]}..."):
                            st.write(f"**ì›ë¬¸:** {criteria.original_text}")
                            if criteria.queryable_parts:
                                st.write(f"**ê²€ì¦ ê°€ëŠ¥ ë¶€ë¶„:** {', '.join(criteria.queryable_parts)}")
                            if criteria.suggested_query_approach:
                                st.write(f"**ì¿¼ë¦¬ ì ‘ê·¼ë²•:** {criteria.suggested_query_approach}")

                with col2:
                    st.write("**âŒ ê²€ì¦ ì–´ë ¤ìš´ ê¸°ì¤€ë“¤:**")
                    non_queryable_criteria = [c for c in result['inclusion_analysis'] + result['exclusion_analysis']
                                            if c.overall_queryability.value == 'LOW']

                    for i, criteria in enumerate(non_queryable_criteria[:5], 1):  # Show top 5
                        with st.expander(f"{i}. {criteria.original_text[:50]}..."):
                            st.write(f"**ì›ë¬¸:** {criteria.original_text}")
                            if criteria.non_queryable_parts:
                                st.write(f"**ì œì•½ ì‚¬í•­:** {', '.join(criteria.non_queryable_parts)}")
                            if criteria.practical_notes:
                                st.write(f"**ì‹¤ë¬´ ê³ ë ¤ì‚¬í•­:** {criteria.practical_notes}")

                # Report generation
                st.divider()
                if st.button("ğŸ“„ ë¶„ì„ ë³´ê³ ì„œ ìƒì„±", type="secondary", key="generate_criteria_report"):
                    report = st.session_state.criteria_analyzer.generate_report(result)
                    st.subheader("ğŸ“‹ ì„ìƒì‹œí—˜ ê¸°ì¤€ ë¶„ì„ ë³´ê³ ì„œ")
                    st.text(report)

else:
    if not CLINICAL_TRIAL_AVAILABLE:
        st.info("ì„ìƒì‹œí—˜ ìŠ¤í¬ë¦¬ë‹ ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ë ¤ë©´ clinical_trial_agent.py íŒŒì¼ì´ í•„ìš”í•©ë‹ˆë‹¤.")
