"""
Phase 15: NL2SQL Generalization Testing
í…ŒìŠ¤íŠ¸ í”„ë ˆì„ì›Œí¬ with API Rate Limit Handling
"""

import sys
import time
import json
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Any

# Add parent directory to path for imports
sys.path.append(str(Path(__file__).parent.parent))

from pipelines.nl2sql_generator import NL2SQLGenerator
from services.databricks_client import DatabricksClient


class NL2SQLTester:
    """NL2SQL í…ŒìŠ¤íŠ¸ ìë™í™” í”„ë ˆì„ì›Œí¬"""

    def __init__(self, batch_size: int = 5, delay_seconds: int = 10):
        """
        ì´ˆê¸°í™”

        Args:
            batch_size: ë°°ì¹˜ë‹¹ ì²˜ë¦¬í•  ì¿¼ë¦¬ ìˆ˜ (API rate limit íšŒí”¼)
            delay_seconds: ë°°ì¹˜ ê°„ ëŒ€ê¸° ì‹œê°„ (ì´ˆ)
        """
        self.generator = NL2SQLGenerator()
        self.databricks = DatabricksClient()
        self.batch_size = batch_size
        self.delay_seconds = delay_seconds

        # Test cases organized by category
        self.test_cases = self._load_test_cases()

        # Results storage
        self.results = []

    def _load_test_cases(self) -> Dict[str, List[Dict[str, str]]]:
        """í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ë¡œë“œ"""
        return {
            "multi_table_joins": [
                {
                    "id": "MTJ-01",
                    "query": "ê³ í˜ˆì••(AI1) í™˜ì ì¤‘ ë‹¹ë‡¨(AE1)ë„ í•¨ê»˜ ìˆëŠ” í™˜ì ìˆ˜ëŠ”?",
                    "expected_features": ["JOIN", "res_disease_code LIKE 'AI1%'", "res_disease_code LIKE 'AE1%'"]
                },
                {
                    "id": "MTJ-02",
                    "query": "ì„œìš¸ ì§€ì—­ 65ì„¸ ì´ìƒ í™˜ìì˜ í‰ê·  ì²˜ë°© ì•½í’ˆ ìˆ˜ëŠ”?",
                    "expected_features": ["JOIN", "TO_DATE(birthday", "res_city LIKE '%ì„œìš¸%'"]
                },
                {
                    "id": "MTJ-03",
                    "query": "ìµœê·¼ 1ë…„ê°„ ì§„ë£Œë°›ì€ í™˜ìì˜ ì§ˆë³‘ë³„ ë¶„í¬ë¥¼ ì•Œë ¤ì¤˜",
                    "expected_features": ["JOIN", "TO_DATE(res_treat_start_date", "GROUP BY"]
                },
                {
                    "id": "MTJ-04",
                    "query": "ë‚¨ì„± í™˜ì ì¤‘ ì²˜ë°©ë°›ì€ ì•½ë¬¼ ì¢…ë¥˜ê°€ 5ê°œ ì´ìƒì¸ ì‚¬ëŒì€?",
                    "expected_features": ["JOIN", "gender = 'M'", "COUNT", "HAVING"]
                },
                {
                    "id": "MTJ-05",
                    "query": "2020ë…„ ì´í›„ ì§„ë£Œë°›ì€ í™˜ìì˜ ì§€ì—­ë³„ í‰ê·  ì—°ë ¹ì€?",
                    "expected_features": ["JOIN", "TO_DATE(res_treat_start_date", "TO_DATE(birthday", "GROUP BY res_city"]
                }
            ],

            "nested_subqueries": [
                {
                    "id": "NSQ-01",
                    "query": "í‰ê·  ì—°ë ¹ë³´ë‹¤ ë†’ì€ í™˜ìë§Œ í•„í„°ë§í•´ì„œ ì§ˆë³‘ ë¶„í¬ ë³´ì—¬ì¤˜",
                    "expected_features": ["SELECT", "FROM", "WHERE", "AVG", "TO_DATE(birthday"]
                },
                {
                    "id": "NSQ-02",
                    "query": "ì²˜ë°© íšŸìˆ˜ê°€ ê°€ì¥ ë§ì€ ìƒìœ„ 10ê°œ ì•½ë¬¼ì„ ì²˜ë°©ë°›ì€ í™˜ì ìˆ˜ëŠ”?",
                    "expected_features": ["IN", "SELECT", "ORDER BY", "LIMIT 10"]
                },
                {
                    "id": "NSQ-03",
                    "query": "ì„œìš¸ ì§€ì—­ í™˜ì í‰ê· ë³´ë‹¤ ì²˜ë°© ì•½ë¬¼ì´ ë§ì€ í™˜ì ëª©ë¡",
                    "expected_features": ["WHERE", "COUNT", "AVG", "res_city LIKE '%ì„œìš¸%'"]
                },
                {
                    "id": "NSQ-04",
                    "query": "ìµœê·¼ 1ë…„ê°„ ì§„ë£Œ í™˜ì ì¤‘ ê³ í˜ˆì•• í™˜ì ë¹„ìœ¨ì€?",
                    "expected_features": ["SELECT", "COUNT", "WHERE", "TO_DATE(res_treat_start_date"]
                },
                {
                    "id": "NSQ-05",
                    "query": "ê°€ì¥ ë§ì´ ì²˜ë°©ë˜ëŠ” ì•½ë¬¼ TOP 5ë¥¼ ë°›ì€ í™˜ìì˜ í‰ê·  ì—°ë ¹",
                    "expected_features": ["IN", "SELECT", "ORDER BY", "LIMIT 5", "AVG", "TO_DATE(birthday"]
                }
            ],

            "window_functions": [
                {
                    "id": "WF-01",
                    "query": "ê° ì§ˆë³‘ë³„ë¡œ í™˜ì ìˆ˜ ìˆœìœ„ë¥¼ ë§¤ê²¨ì¤˜ (RANK ì‚¬ìš©)",
                    "expected_features": ["RANK()", "OVER", "PARTITION BY", "ORDER BY"]
                },
                {
                    "id": "WF-02",
                    "query": "ì§€ì—­ë³„ í™˜ì ìˆ˜ë¥¼ ê³„ì‚°í•˜ê³  ì „ì²´ í™˜ì ëŒ€ë¹„ ë¹„ìœ¨ë„ ê°™ì´ ë³´ì—¬ì¤˜",
                    "expected_features": ["COUNT", "SUM", "OVER()", "GROUP BY res_city"]
                },
                {
                    "id": "WF-03",
                    "query": "ì—°ë ¹ëŒ€ë³„ í™˜ì ìˆ˜ë¥¼ ê³„ì‚°í•˜ê³  ëˆ„ì  í•©ê³„ë„ í‘œì‹œí•´ì¤˜",
                    "expected_features": ["SUM", "OVER", "ORDER BY", "TO_DATE(birthday"]
                },
                {
                    "id": "WF-04",
                    "query": "ê° ì•½ë¬¼ì˜ ì²˜ë°© íšŸìˆ˜ë¥¼ ê³„ì‚°í•˜ê³  ìƒìœ„ 10%ë¥¼ í‘œì‹œí•´ì¤˜",
                    "expected_features": ["PERCENT_RANK()", "OVER", "ORDER BY", "WHERE"]
                },
                {
                    "id": "WF-05",
                    "query": "ì§ˆë³‘ë³„ í™˜ì ìˆ˜ì™€ ì´ì „ ì§ˆë³‘ ëŒ€ë¹„ ì¦ê°ë¥  ê³„ì‚°",
                    "expected_features": ["LAG()", "OVER", "ORDER BY", "COUNT"]
                }
            ],

            "complex_aggregations": [
                {
                    "id": "CA-01",
                    "query": "ì„±ë³„, ì—°ë ¹ëŒ€ë³„ í™˜ì ìˆ˜ë¥¼ êµì°¨ ì§‘ê³„í•´ì¤˜",
                    "expected_features": ["GROUP BY", "CASE WHEN", "TO_DATE(birthday", "gender"]
                },
                {
                    "id": "CA-02",
                    "query": "ì§€ì—­ë³„ë¡œ ê°€ì¥ ë§ì€ ì§ˆë³‘ TOP 3ì„ ì°¾ì•„ì¤˜",
                    "expected_features": ["GROUP BY", "COUNT", "ORDER BY", "LIMIT"]
                },
                {
                    "id": "CA-03",
                    "query": "ì›”ë³„ ì‹ ê·œ í™˜ì ìˆ˜ ì¶”ì´ë¥¼ ë³´ì—¬ì¤˜ (ìµœê·¼ 1ë…„)",
                    "expected_features": ["DATE_FORMAT", "TO_DATE", "GROUP BY", "COUNT"]
                },
                {
                    "id": "CA-04",
                    "query": "ì•½ë¬¼ë³„ ì²˜ë°© í™˜ìì˜ í‰ê·  ì—°ë ¹, ì¤‘ì•™ê°’, í‘œì¤€í¸ì°¨ ê³„ì‚°",
                    "expected_features": ["AVG", "PERCENTILE_APPROX", "STDDEV", "GROUP BY"]
                },
                {
                    "id": "CA-05",
                    "query": "ì§ˆë³‘ë³„ ë‚¨ë…€ ë¹„ìœ¨ê³¼ í‰ê·  ì—°ë ¹ì„ í•œ ë²ˆì— ë³´ì—¬ì¤˜",
                    "expected_features": ["GROUP BY", "COUNT", "CASE", "AVG", "TO_DATE(birthday"]
                }
            ],

            "date_range_queries": [
                {
                    "id": "DRQ-01",
                    "query": "2023ë…„ 1ì›”ë¶€í„° 2023ë…„ 12ì›”ê¹Œì§€ ì§„ë£Œë°›ì€ í™˜ì ìˆ˜ëŠ”?",
                    "expected_features": ["TO_DATE(res_treat_start_date", "BETWEEN", "2023"]
                },
                {
                    "id": "DRQ-02",
                    "query": "ìµœê·¼ 3ê°œì›”ê°„ ì‹ ê·œ ë“±ë¡ëœ í™˜ìì˜ ì§ˆë³‘ ë¶„í¬ëŠ”?",
                    "expected_features": ["TO_DATE", ">=", "DATE_SUB", "CURRENT_DATE"]
                },
                {
                    "id": "DRQ-03",
                    "query": "1980ë…„ëŒ€ ì¶œìƒ í™˜ì ì¤‘ ê³ í˜ˆì•• í™˜ì ë¹„ìœ¨ì€?",
                    "expected_features": ["TO_DATE(birthday", "BETWEEN", "1980", "1989"]
                },
                {
                    "id": "DRQ-04",
                    "query": "ê° ë¶„ê¸°ë³„ ì§„ë£Œ í™˜ì ìˆ˜ ì¶”ì´ë¥¼ ë³´ì—¬ì¤˜ (2022-2023)",
                    "expected_features": ["QUARTER", "TO_DATE(res_treat_start_date", "GROUP BY"]
                },
                {
                    "id": "DRQ-05",
                    "query": "60ì„¸ ì´ìƒ í™˜ì ì¤‘ ìµœê·¼ 6ê°œì›”ê°„ ì§„ë£Œë°›ì€ ì‚¬ëŒì€?",
                    "expected_features": ["TO_DATE(birthday", "TO_DATE(res_treat_start_date", "DATE_SUB"]
                }
            ]
        }

    def run_all_tests(self) -> Dict[str, Any]:
        """ì „ì²´ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        print("=" * 80)
        print("Phase 15: NL2SQL Generalization Testing")
        print("=" * 80)
        print(f"ì´ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤: {sum(len(cases) for cases in self.test_cases.values())}ê°œ")
        print(f"ë°°ì¹˜ í¬ê¸°: {self.batch_size}, ë°°ì¹˜ ê°„ ëŒ€ê¸°: {self.delay_seconds}ì´ˆ\n")

        start_time = datetime.now()

        # Categoryë³„ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
        for category, test_cases in self.test_cases.items():
            print(f"\n{'=' * 80}")
            print(f"Category: {category.replace('_', ' ').title()}")
            print(f"{'=' * 80}\n")

            self._run_category_tests(category, test_cases)

        end_time = datetime.now()
        duration = (end_time - start_time).total_seconds()

        # ê²°ê³¼ ì§‘ê³„
        summary = self._calculate_summary(duration)

        # ê²°ê³¼ ì €ì¥
        self._save_results(summary)

        # ìµœì¢… ë¦¬í¬íŠ¸ ì¶œë ¥
        self._print_summary(summary)

        return summary

    def _run_category_tests(self, category: str, test_cases: List[Dict]):
        """ì¹´í…Œê³ ë¦¬ë³„ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ (ë°°ì¹˜ ì²˜ë¦¬)"""
        for i, test_case in enumerate(test_cases, 1):
            print(f"[{test_case['id']}] Testing: {test_case['query']}")

            result = self._test_single_query(test_case, category)
            self.results.append(result)

            # ìƒíƒœ í‘œì‹œ
            status_icon = "âœ…" if result['sql_generated'] else "âŒ"
            exec_icon = "âœ…" if result['execution_success'] else "âŒ" if result['executed'] else "â­ï¸"
            print(f"  {status_icon} SQL ìƒì„± | {exec_icon} ì‹¤í–‰\n")

            # ë°°ì¹˜ ê°„ ëŒ€ê¸° (API rate limit íšŒí”¼)
            if i % self.batch_size == 0 and i < len(test_cases):
                print(f"â¸ï¸  ë°°ì¹˜ ì™„ë£Œ ({i}/{len(test_cases)}). {self.delay_seconds}ì´ˆ ëŒ€ê¸° ì¤‘...\n")
                time.sleep(self.delay_seconds)

    def _test_single_query(self, test_case: Dict, category: str) -> Dict[str, Any]:
        """ë‹¨ì¼ ì¿¼ë¦¬ í…ŒìŠ¤íŠ¸"""
        result = {
            'id': test_case['id'],
            'category': category,
            'query': test_case['query'],
            'expected_features': test_case['expected_features'],
            'timestamp': datetime.now().isoformat(),
            'sql_generated': False,
            'generated_sql': None,
            'execution_attempted': False,
            'executed': False,
            'execution_success': False,
            'row_count': None,
            'execution_time': None,
            'error_message': None,
            'feature_matches': [],
            'feature_match_rate': 0.0
        }

        # Step 1: SQL ìƒì„±
        try:
            nl2sql_result = self.generator.generate_sql(test_case['query'])

            if nl2sql_result.success:
                result['sql_generated'] = True
                result['generated_sql'] = nl2sql_result.sql_query

                # Feature ë§¤ì¹­ ê²€ì‚¬
                matches = [
                    feature for feature in test_case['expected_features']
                    if feature.lower() in nl2sql_result.sql_query.lower()
                ]
                result['feature_matches'] = matches
                result['feature_match_rate'] = len(matches) / len(test_case['expected_features'])
            else:
                result['error_message'] = nl2sql_result.error_message
                return result

        except Exception as e:
            result['error_message'] = f"SQL ìƒì„± ì¤‘ ì˜ˆì™¸: {str(e)}"
            return result

        # Step 2: SQL ì‹¤í–‰ (ìƒì„± ì„±ê³µ ì‹œë§Œ)
        if result['sql_generated']:
            result['execution_attempted'] = True
            try:
                exec_result = self.databricks.execute_query(result['generated_sql'])

                if exec_result['success']:
                    result['executed'] = True
                    result['execution_success'] = True
                    result['row_count'] = exec_result['row_count']
                    result['execution_time'] = exec_result.get('execution_time')
                else:
                    result['executed'] = True
                    result['execution_success'] = False
                    result['error_message'] = exec_result.get('error')

            except Exception as e:
                result['executed'] = True
                result['execution_success'] = False
                result['error_message'] = f"ì‹¤í–‰ ì¤‘ ì˜ˆì™¸: {str(e)}"

        return result

    def _calculate_summary(self, duration: float) -> Dict[str, Any]:
        """ê²°ê³¼ í†µê³„ ê³„ì‚°"""
        total = len(self.results)
        sql_generated = sum(1 for r in self.results if r['sql_generated'])
        executed = sum(1 for r in self.results if r['executed'])
        execution_success = sum(1 for r in self.results if r['execution_success'])

        # Categoryë³„ í†µê³„
        category_stats = {}
        for category in self.test_cases.keys():
            cat_results = [r for r in self.results if r['category'] == category]
            category_stats[category] = {
                'total': len(cat_results),
                'sql_generated': sum(1 for r in cat_results if r['sql_generated']),
                'execution_success': sum(1 for r in cat_results if r['execution_success']),
                'avg_feature_match': sum(r['feature_match_rate'] for r in cat_results) / len(cat_results) if cat_results else 0
            }

        # Feature matching í†µê³„
        avg_feature_match = sum(r['feature_match_rate'] for r in self.results) / total if total > 0 else 0

        return {
            'test_date': datetime.now().isoformat(),
            'total_duration_seconds': round(duration, 2),
            'total_tests': total,
            'sql_generation': {
                'success_count': sql_generated,
                'failure_count': total - sql_generated,
                'success_rate': round(sql_generated / total * 100, 2) if total > 0 else 0
            },
            'execution': {
                'attempted': executed,
                'success_count': execution_success,
                'failure_count': executed - execution_success,
                'success_rate': round(execution_success / executed * 100, 2) if executed > 0 else 0
            },
            'feature_matching': {
                'avg_match_rate': round(avg_feature_match * 100, 2)
            },
            'category_breakdown': category_stats,
            'detailed_results': self.results
        }

    def _save_results(self, summary: Dict[str, Any]):
        """ê²°ê³¼ ì €ì¥"""
        output_dir = Path(__file__).parent / "results"
        output_dir.mkdir(exist_ok=True)

        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_file = output_dir / f"nl2sql_test_results_{timestamp}.json"

        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(summary, f, ensure_ascii=False, indent=2)

        print(f"\nğŸ’¾ ê²°ê³¼ ì €ì¥: {output_file}")

    def _print_summary(self, summary: Dict[str, Any]):
        """ìµœì¢… ë¦¬í¬íŠ¸ ì¶œë ¥"""
        print("\n" + "=" * 80)
        print("ğŸ“Š Phase 15 Test Results Summary")
        print("=" * 80)

        print(f"\nâ±ï¸  ì´ ì†Œìš” ì‹œê°„: {summary['total_duration_seconds']}ì´ˆ")
        print(f"ğŸ“ ì´ í…ŒìŠ¤íŠ¸: {summary['total_tests']}ê°œ\n")

        print("ğŸ”¹ SQL ìƒì„± ì„±ê³µë¥ ")
        print(f"   ì„±ê³µ: {summary['sql_generation']['success_count']}ê°œ")
        print(f"   ì‹¤íŒ¨: {summary['sql_generation']['failure_count']}ê°œ")
        print(f"   ì„±ê³µë¥ : {summary['sql_generation']['success_rate']}%\n")

        print("ğŸ”¹ SQL ì‹¤í–‰ ì„±ê³µë¥ ")
        print(f"   ì‹œë„: {summary['execution']['attempted']}ê°œ")
        print(f"   ì„±ê³µ: {summary['execution']['success_count']}ê°œ")
        print(f"   ì‹¤íŒ¨: {summary['execution']['failure_count']}ê°œ")
        print(f"   ì„±ê³µë¥ : {summary['execution']['success_rate']}%\n")

        print(f"ğŸ”¹ Feature ë§¤ì¹­ë¥ : {summary['feature_matching']['avg_match_rate']}%\n")

        print("ğŸ“‚ Categoryë³„ ê²°ê³¼:")
        for category, stats in summary['category_breakdown'].items():
            print(f"   {category}:")
            print(f"      SQL ìƒì„±: {stats['sql_generated']}/{stats['total']}")
            print(f"      ì‹¤í–‰ ì„±ê³µ: {stats['execution_success']}/{stats['total']}")
            print(f"      Feature ë§¤ì¹­: {stats['avg_feature_match']:.1%}")

        print("\n" + "=" * 80)

        # ëª©í‘œ ë‹¬ì„± ì—¬ë¶€
        sql_target = 84
        exec_target = 90
        sql_rate = summary['sql_generation']['success_rate']
        exec_rate = summary['execution']['success_rate']

        print("\nğŸ¯ ëª©í‘œ ë‹¬ì„± ì—¬ë¶€:")
        print(f"   SQL ìƒì„± ì„±ê³µë¥ : {sql_rate}% (ëª©í‘œ: {sql_target}%+) {'âœ…' if sql_rate >= sql_target else 'âŒ'}")
        print(f"   ì‹¤í–‰ ì„±ê³µë¥ : {exec_rate}% (ëª©í‘œ: {exec_target}%+) {'âœ…' if exec_rate >= exec_target else 'âŒ'}")


if __name__ == "__main__":
    tester = NL2SQLTester(batch_size=5, delay_seconds=10)
    summary = tester.run_all_tests()
