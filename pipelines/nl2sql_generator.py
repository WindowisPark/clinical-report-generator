"""
RAG-based Natural Language to SQL Generator (Pattern II)
ìŠ¤í‚¤ë§ˆ ë©”íƒ€ë°ì´í„°ì™€ ì°¸ì¡° ë°ì´í„°ë¥¼ í™œìš©í•œ Text-to-SQL ì‹œìŠ¤í…œ
"""

import os
import pandas as pd
import google.generativeai as genai
from typing import Dict, List, Optional
from dataclasses import dataclass
import json
import re

from config.config_loader import get_config
from core.schema_loader import SchemaLoader
from prompts.loader import PromptLoader
from utils.logger import setup_logger, log_nl2sql_generation


@dataclass
class SQLGenerationResult:
    """SQL ìƒì„± ê²°ê³¼"""
    success: bool
    sql_query: str
    analysis: Dict
    error_message: Optional[str] = None
    referenced_tables: List[str] = None
    relevant_examples: List[str] = None


class NL2SQLGenerator:
    """RAG ê¸°ë°˜ ìì—°ì–´ â†’ SQL ë³€í™˜ê¸°"""

    def __init__(self, enable_logging: bool = True):
        """ì´ˆê¸°í™”"""
        self.gemini_model = self._initialize_gemini()

        # === RAG Enhancement: Unified SchemaLoader ===
        self.schema_loader = SchemaLoader()
        self.reference_data = self._load_reference_data()

        # === Prompt Optimization: PromptLoader ===
        self.prompt_loader = PromptLoader()

        # ì˜ˆì‹œ SQL ì¿¼ë¦¬ (Few-shot learningìš©)
        self.example_queries = self._load_example_queries()

        # === Logging ===
        self.logger = setup_logger("nl2sql_generator") if enable_logging else None

        print(f"âœ… NL2SQL Generator ì´ˆê¸°í™” ì™„ë£Œ (RAG Enhanced + Prompt Optimized)")
        print(f"  - Schema: databricks_schema_for_rag.csv (unified)")
        print(f"  - ì°¸ì¡° ë°ì´í„°: {len(self.reference_data)} categories")
        print(f"  - ì˜ˆì‹œ ì¿¼ë¦¬: {len(self.example_queries)}ê°œ")
        print(f"  - Prompt: External templates (optimized)")
        print(f"  - Logging: {'Enabled' if enable_logging else 'Disabled'}")

    def _initialize_gemini(self):
        """Gemini API ì´ˆê¸°í™” (centralized config)"""
        config = get_config()
        api_key = config.get_gemini_api_key()

        genai.configure(api_key=api_key)
        return genai.GenerativeModel('gemini-2.0-flash-exp')

    # Removed: _load_notion_columns() - now using SchemaLoader

    def _load_reference_data(self) -> Dict[str, pd.DataFrame]:
        """ì°¸ì¡° ë°ì´í„° ë¡œë“œ (ì „ì²´ ë¡œë“œ - RAG ìš©)"""
        reference_dir = "reference_data"
        ref_data = {}

        files = {
            'diseases': 'unique_diseases.csv',
            'drugs': 'unique_drugs.csv',
            'ingredients': 'unique_ingredients.csv',
        }

        for key, filename in files.items():
            filepath = os.path.join(reference_dir, filename)
            if os.path.exists(filepath):
                # RAG ê°œì„ : ì „ì²´ ë°ì´í„° ë¡œë“œ (ì§ˆë³‘ ì½”ë“œ ë§¤í•‘ìš©)
                df = pd.read_csv(filepath)
                ref_data[key] = df

        return ref_data

    def _load_example_queries(self) -> List[Dict]:
        """Few-shot learningì„ ìœ„í•œ ì˜ˆì‹œ ì¿¼ë¦¬"""
        return [
            {
                "question": "ê³ í˜ˆì•• í™˜ìì˜ ë‚¨ë…€ ì„±ë³„ ë¶„í¬ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”",
                "sql": """SELECT
    ip.gender AS `ì„±ë³„`,
    COUNT(DISTINCT bt.user_id) AS `í™˜ììˆ˜`
FROM basic_treatment bt
JOIN insured_person ip ON bt.user_id = ip.user_id
WHERE bt.deleted = FALSE
    AND bt.res_disease_code LIKE 'AI1%'
GROUP BY ip.gender
ORDER BY `í™˜ììˆ˜` DESC""",
                "tables": ["basic_treatment", "insured_person"]
            },
            {
                "question": "ë‹¹ë‡¨ë³‘ í™˜ìì—ê²Œ ê°€ì¥ ë§ì´ ì²˜ë°©ëœ ì•½ë¬¼ TOP 5",
                "sql": """SELECT
    pd.res_drug_name AS `ì•½ë¬¼ëª…`,
    COUNT(*) AS `ì²˜ë°©íšŸìˆ˜`
FROM basic_treatment bt
JOIN prescribed_drug pd
    ON bt.user_id = pd.user_id
    AND bt.res_treat_start_date = pd.res_treat_start_date
WHERE bt.deleted = FALSE
    AND pd.deleted = FALSE
    AND bt.res_disease_code LIKE 'AE1%'
GROUP BY pd.res_drug_name
ORDER BY `ì²˜ë°©íšŸìˆ˜` DESC
LIMIT 5""",
                "tables": ["basic_treatment", "prescribed_drug"]
            },
            {
                "question": "ì„œìš¸ ì§€ì—­ ë³‘ì›ì—ì„œ ì¹˜ë£Œë°›ì€ ì•” í™˜ì ìˆ˜",
                "sql": """SELECT
    COUNT(DISTINCT user_id) AS `í™˜ììˆ˜`
FROM basic_treatment
WHERE deleted = FALSE
    AND res_disease_code LIKE 'AC%'
    AND res_hospital_name LIKE '%ì„œìš¸%'""",
                "tables": ["basic_treatment"]
            },
            {
                "question": "ìµœê·¼ 1ë…„ê°„ ì¡°í˜„ë³‘ìœ¼ë¡œ ì¹˜ë£Œë°›ì€ í™˜ì ìˆ˜",
                "sql": """SELECT
    COUNT(DISTINCT user_id) AS `í™˜ììˆ˜`
FROM basic_treatment
WHERE deleted = FALSE
    AND res_disease_code LIKE 'AF2%'
    AND TRY_TO_DATE(res_treat_start_date, 'yyyyMMdd') >= DATE_SUB(CURRENT_DATE, 365)""",
                "tables": ["basic_treatment"]
            },
            {
                "question": "20ëŒ€ ì—¬ì„± ë¹„ë§Œ í™˜ìì—ê²Œ ê°€ì¥ ë§ì´ ì²˜ë°©ëœ ì•½ë¬¼ TOP 10",
                "sql": """SELECT
    pd.res_drug_name AS `ì•½ë¬¼ëª…`,
    COUNT(*) AS `ì²˜ë°©íšŸìˆ˜`
FROM basic_treatment bt
JOIN insured_person ip ON bt.user_id = ip.user_id
JOIN prescribed_drug pd ON bt.user_id = pd.user_id AND bt.res_treat_start_date = pd.res_treat_start_date
WHERE bt.deleted = FALSE
    AND pd.deleted = FALSE
    AND ip.gender = 'WOMAN'
    AND YEAR(CURRENT_DATE) - YEAR(TRY_TO_DATE(ip.birthday, 'yyyyMMdd')) BETWEEN 20 AND 29
    AND bt.res_disease_code LIKE 'AE66%'
GROUP BY pd.res_drug_name
ORDER BY `ì²˜ë°©íšŸìˆ˜` DESC
LIMIT 10""",
                "tables": ["basic_treatment", "insured_person", "prescribed_drug"]
            },
            {
                "question": "ì„œìš¸ ì§€ì—­ 65ì„¸ ì´ìƒ í™˜ìì˜ í‰ê·  ì²˜ë°© ì•½í’ˆ ìˆ˜",
                "sql": """-- ì„œìš¸ ì§€ì—­ 65ì„¸ ì´ìƒ í™˜ìì˜ í‰ê·  ì²˜ë°© ì•½í’ˆ ìˆ˜
SELECT
    AVG(drug_count) AS `í‰ê·  ì²˜ë°© ì•½í’ˆ ìˆ˜`
FROM (
    SELECT
        bt.user_id,
        COUNT(DISTINCT pd.res_drug_name) AS drug_count
    FROM basic_treatment bt
    JOIN insured_person ip ON bt.user_id = ip.user_id
    LEFT JOIN prescribed_drug pd
        ON bt.user_id = pd.user_id
        AND bt.res_treat_start_date = pd.res_treat_start_date
    WHERE bt.res_hospital_name LIKE '%ì„œìš¸%'
        AND YEAR(CURRENT_DATE) - YEAR(TRY_TO_DATE(ip.birthday, 'yyyyMMdd')) >= 65
        AND bt.deleted = FALSE
        AND pd.deleted = FALSE
    GROUP BY bt.user_id
) AS subquery""",
                "tables": ["basic_treatment", "insured_person", "prescribed_drug"]
            },
            {
                "question": "ê° ì§ˆë³‘ë³„ë¡œ í™˜ì ìˆ˜ ìˆœìœ„ë¥¼ ë§¤ê²¨ì¤˜ (RANK ì‚¬ìš©)",
                "sql": """-- ì§ˆë³‘ë³„ í™˜ì ìˆ˜ ìˆœìœ„
SELECT
    res_disease_name AS `ì§ˆë³‘ëª…`,
    patient_count AS `í™˜ììˆ˜`,
    RANK() OVER (ORDER BY patient_count DESC) AS `ìˆœìœ„`
FROM (
    SELECT
        res_disease_name,
        COUNT(DISTINCT user_id) AS patient_count
    FROM basic_treatment
    WHERE deleted = FALSE
    GROUP BY res_disease_name
) AS disease_counts
ORDER BY `ìˆœìœ„`
LIMIT 100""",
                "tables": ["basic_treatment"]
            },
            {
                "question": "ì—°ë ¹ëŒ€ë³„ í™˜ì ìˆ˜ë¥¼ ê³„ì‚°í•˜ê³  ëˆ„ì  í•©ê³„ë„ í‘œì‹œí•´ì¤˜",
                "sql": """-- ì—°ë ¹ëŒ€ë³„ í™˜ì ìˆ˜ ë° ëˆ„ì  í•©ê³„
WITH AgeGroupCounts AS (
    SELECT
        CASE
            WHEN YEAR(CURRENT_DATE) - YEAR(TRY_TO_DATE(ip.birthday, 'yyyyMMdd')) < 30 THEN '20ëŒ€ ì´í•˜'
            WHEN YEAR(CURRENT_DATE) - YEAR(TRY_TO_DATE(ip.birthday, 'yyyyMMdd')) < 40 THEN '30ëŒ€'
            WHEN YEAR(CURRENT_DATE) - YEAR(TRY_TO_DATE(ip.birthday, 'yyyyMMdd')) < 50 THEN '40ëŒ€'
            WHEN YEAR(CURRENT_DATE) - YEAR(TRY_TO_DATE(ip.birthday, 'yyyyMMdd')) < 60 THEN '50ëŒ€'
            ELSE '60ëŒ€ ì´ìƒ'
        END AS age_group,
        COUNT(DISTINCT bt.user_id) AS patient_count
    FROM basic_treatment bt
    JOIN insured_person ip ON bt.user_id = ip.user_id
    WHERE bt.deleted = FALSE
        AND TRY_TO_DATE(ip.birthday, 'yyyyMMdd') IS NOT NULL
    GROUP BY age_group
)
SELECT
    age_group AS `ì—°ë ¹ëŒ€`,
    patient_count AS `í™˜ììˆ˜`,
    SUM(patient_count) OVER (
        ORDER BY CASE
            WHEN age_group = '20ëŒ€ ì´í•˜' THEN 1
            WHEN age_group = '30ëŒ€' THEN 2
            WHEN age_group = '40ëŒ€' THEN 3
            WHEN age_group = '50ëŒ€' THEN 4
            ELSE 5
        END
    ) AS `ëˆ„ì  í•©ê³„`
FROM AgeGroupCounts
ORDER BY
    CASE
        WHEN age_group = '20ëŒ€ ì´í•˜' THEN 1
        WHEN age_group = '30ëŒ€' THEN 2
        WHEN age_group = '40ëŒ€' THEN 3
        WHEN age_group = '50ëŒ€' THEN 4
        ELSE 5
    END""",
                "tables": ["basic_treatment", "insured_person"]
            },
            {
                "question": "ì„±ë³„, ì—°ë ¹ëŒ€ë³„ í™˜ì ìˆ˜ë¥¼ êµì°¨ ì§‘ê³„í•´ì¤˜",
                "sql": """-- ì„±ë³„ Ã— ì—°ë ¹ëŒ€ êµì°¨ ì§‘ê³„
SELECT
    ip.gender AS `ì„±ë³„`,
    CASE
        WHEN YEAR(CURRENT_DATE) - YEAR(TRY_TO_DATE(ip.birthday, 'yyyyMMdd')) < 30 THEN '20ëŒ€ ì´í•˜'
        WHEN YEAR(CURRENT_DATE) - YEAR(TRY_TO_DATE(ip.birthday, 'yyyyMMdd')) < 40 THEN '30ëŒ€'
        WHEN YEAR(CURRENT_DATE) - YEAR(TRY_TO_DATE(ip.birthday, 'yyyyMMdd')) < 50 THEN '40ëŒ€'
        WHEN YEAR(CURRENT_DATE) - YEAR(TRY_TO_DATE(ip.birthday, 'yyyyMMdd')) < 60 THEN '50ëŒ€'
        ELSE '60ëŒ€ ì´ìƒ'
    END AS `ì—°ë ¹ëŒ€`,
    COUNT(DISTINCT bt.user_id) AS `í™˜ììˆ˜`
FROM basic_treatment bt
JOIN insured_person ip ON bt.user_id = ip.user_id
WHERE bt.deleted = FALSE
    AND TRY_TO_DATE(ip.birthday, 'yyyyMMdd') IS NOT NULL
GROUP BY ip.gender, `ì—°ë ¹ëŒ€`
ORDER BY ip.gender, `ì—°ë ¹ëŒ€`""",
                "tables": ["basic_treatment", "insured_person"]
            },
            {
                "question": "2023ë…„ 1ì›”ë¶€í„° 12ì›”ê¹Œì§€ ì§„ë£Œë°›ì€ í™˜ì ìˆ˜ëŠ”?",
                "sql": """-- íŠ¹ì • ê¸°ê°„ í™˜ì ìˆ˜ (BETWEEN ì‚¬ìš©)
SELECT
    COUNT(DISTINCT user_id) AS `í™˜ììˆ˜`
FROM basic_treatment
WHERE deleted = FALSE
    AND TRY_TO_DATE(res_treat_start_date, 'yyyyMMdd')
        BETWEEN TRY_TO_DATE('20230101', 'yyyyMMdd')
        AND TRY_TO_DATE('20231231', 'yyyyMMdd')""",
                "tables": ["basic_treatment"]
            }
        ]

    def _extract_keywords(self, query: str) -> List[str]:
        """ì‚¬ìš©ì ì¿¼ë¦¬ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ"""
        # ì¼ë°˜ í‚¤ì›Œë“œ
        keywords = ['í™˜ì', 'ì²˜ë°©', 'ì•½ë¬¼', 'ë³‘ì›', 'ì§€ì—­', 'ì„±ë³„', 'ì—°ë ¹', 'ë‚¨ì„±', 'ì—¬ì„±',
                   'ë¶„í¬', 'ë¹„ìœ¨', 'ìˆ˜', 'ê°œìˆ˜', 'TOP', 'ìƒìœ„', 'ë§ì´', 'ì ê²Œ']
        medical_keywords = [kw for kw in keywords if kw in query]

        return medical_keywords

    def _find_disease_codes(self, query: str) -> List[Dict[str, str]]:
        """
        RAG: ì¿¼ë¦¬ì—ì„œ ì§ˆë³‘ëª…ì„ ì°¾ì•„ í•´ë‹¹í•˜ëŠ” ì§ˆë³‘ ì½”ë“œ ë°˜í™˜

        Returns:
            List[Dict]: [{'disease_name': 'ê³ í˜ˆì••', 'disease_code': 'AI109', 'pattern': 'AI1%'}, ...]
        """
        disease_matches = []
        diseases_df = self.reference_data.get('diseases', pd.DataFrame())

        if diseases_df.empty:
            return disease_matches

        # ì£¼ìš” ì§ˆë³‘ í‚¤ì›Œë“œ ë§¤í•‘ (ë¶€ë¶„ ë§¤ì¹­ìš©)
        disease_keywords = {
            'ê³ í˜ˆì••': ['ê³ í˜ˆì••'],
            'ë‹¹ë‡¨': ['ë‹¹ë‡¨', 'ë‹¹ë‡¨ë³‘'],
            'ì•”': ['ì•”'],
            'ìœ„ì—¼': ['ìœ„ì—¼'],
            'ê°ê¸°': ['ê°ê¸°', 'ë…ê°'],
            'ì¡°í˜„ë³‘': ['ì¡°í˜„ë³‘'],
            'ë¹„ë§Œ': ['ë¹„ë§Œ'],
            'íë ´': ['íë ´'],
            'ì²œì‹': ['ì²œì‹'],
            'ìš°ìš¸': ['ìš°ìš¸ì¦', 'ìš°ìš¸'],
            'ì¹˜ë§¤': ['ì¹˜ë§¤', 'ì•Œì¸ í•˜ì´ë¨¸'],
            'íŒŒí‚¨ìŠ¨': ['íŒŒí‚¨ìŠ¨'],
            'ê°„ì—¼': ['ê°„ì—¼', 'ê°„ê²½í™”'],
            'ì‹ ë¶€ì „': ['ì‹ ë¶€ì „'],
            'ì‹¬ë¶€ì „': ['ì‹¬ë¶€ì „'],
        }

        # ì¿¼ë¦¬ì—ì„œ ì§ˆë³‘ í‚¤ì›Œë“œ ê°ì§€
        for disease_key, keywords in disease_keywords.items():
            for keyword in keywords:
                if keyword in query:
                    # í•´ë‹¹ ì§ˆë³‘ëª…ì´ í¬í•¨ëœ ì§ˆë³‘ ì½”ë“œ ì°¾ê¸°
                    matching_diseases = diseases_df[
                        diseases_df['name'].str.contains(keyword, na=False, case=False)
                    ].head(3)  # ìƒìœ„ 3ê°œë§Œ

                    for _, row in matching_diseases.iterrows():
                        code = row['code']
                        if code and code != '$':
                            # ì½”ë“œ íŒ¨í„´ ìƒì„± (ì˜ˆ: AI109 â†’ AI1%)
                            pattern = code[:3] + '%' if len(code) >= 3 else code + '%'
                            disease_matches.append({
                                'disease_name': row['name'],
                                'disease_code': code,
                                'pattern': pattern,
                                'keyword': keyword
                            })
                    break  # ì²« ë²ˆì§¸ ë§¤ì¹­ í‚¤ì›Œë“œë§Œ ì‚¬ìš©

        return disease_matches

    # Removed: _search_relevant_schema() - now delegating to SchemaLoader

    # Removed: _create_schema_context() - now using SchemaLoader.format_schema_for_llm()

    def _select_relevant_examples(self, query: str, keywords: List[str]) -> List[Dict]:
        """ì¿¼ë¦¬ì™€ ìœ ì‚¬í•œ ì˜ˆì‹œ ì„ íƒ (ê°œì„ : íŒ¨í„´ ë§¤ì¹­ ê°•í™”)"""
        query_lower = query.lower()

        # ì¿¼ë¦¬ íŒ¨í„´ ê°ì§€
        patterns = {
            'rank': 'rank' in query_lower or 'ìˆœìœ„' in query_lower or 'top' in query_lower.replace('top ', ''),
            'window_func': any(kw in query_lower for kw in ['ìˆœìœ„', 'ëˆ„ì ', 'ë¹„ìœ¨', 'í•©ê³„', 'rank', 'row_number']),
            'aggregation': any(kw in query_lower for kw in ['êµì°¨', 'ì§‘ê³„', 'ë¶„í¬', 'ê·¸ë£¹', 'group']),
            'join': any(kw in query_lower for kw in ['ì„±ë³„', 'ì—°ë ¹', 'ì•½', 'ì²˜ë°©', 'gender', 'age']),
            'date_range': any(kw in query_lower for kw in ['ë…„', 'ì›”', 'ì¼', 'ê¸°ê°„', 'ì´í›„', 'ì´ì „', 'ë™ì•ˆ']),
            'age_filter': any(kw in query_lower for kw in ['ì„¸', 'ì—°ë ¹', 'age']),
            'location': any(kw in query_lower for kw in ['ì§€ì—­', 'ì„œìš¸', 'ë¶€ì‚°', 'ë³‘ì›ëª…'])
        }

        scored_examples = []

        for example in self.example_queries:
            ex_lower = example['question'].lower()
            score = 0

            # íŒ¨í„´ ë§¤ì¹­ ì ìˆ˜ (ê°€ì¤‘ì¹˜ ë†’ìŒ)
            if patterns['rank'] and 'rank' in ex_lower:
                score += 10
            if patterns['window_func'] and any(kw in ex_lower for kw in ['ìˆœìœ„', 'ëˆ„ì ', 'ë¹„ìœ¨']):
                score += 8
            if patterns['aggregation'] and any(kw in ex_lower for kw in ['êµì°¨', 'ì§‘ê³„', 'ë¶„í¬']):
                score += 8
            if patterns['age_filter'] and ('ì„¸' in ex_lower or 'age' in ex_lower):
                score += 7
            if patterns['location'] and any(kw in ex_lower for kw in ['ì§€ì—­', 'ì„œìš¸', 'ë³‘ì›']):
                score += 7
            if patterns['date_range'] and any(kw in ex_lower for kw in ['ë…„', 'ê¸°ê°„', 'ì´í›„']):
                score += 6

            # í‚¤ì›Œë“œ ë§¤ì¹­ ì ìˆ˜
            keyword_matches = sum(1 for kw in keywords if kw in ex_lower)
            score += keyword_matches * 2

            # í…Œì´ë¸” ë³µì¡ë„ ë§¤ì¹­ (JOIN ì—¬ë¶€)
            if patterns['join'] and len(example['tables']) > 1:
                score += 5

            if score > 0:
                scored_examples.append((score, example))

        # ì ìˆ˜ ìˆœìœ¼ë¡œ ì •ë ¬í•˜ì—¬ ìƒìœ„ 3ê°œ ë°˜í™˜ (2ê°œ â†’ 3ê°œë¡œ ì¦ê°€)
        scored_examples.sort(key=lambda x: x[0], reverse=True)
        return [ex for score, ex in scored_examples[:3]]

    def _create_llm_prompt(self, query: str, schema_context: str, examples: List[Dict], disease_hints: str = "") -> str:
        """LLM í”„ë¡¬í”„íŠ¸ ìƒì„± (PromptLoader ì‚¬ìš© + ì§ˆë³‘ ì½”ë“œ íŒíŠ¸)"""
        base_prompt = self.prompt_loader.load_nl2sql_prompt(
            user_query=query,
            schema_context=schema_context,
            relevant_examples=examples
        )

        # RAG ê°œì„ : ì§ˆë³‘ ì½”ë“œ íŒíŠ¸ ì¶”ê°€
        if disease_hints:
            base_prompt += f"\n\n## ğŸ¯ ì§ˆë³‘ ì½”ë“œ íŒíŠ¸ (RAG ìë™ ê²€ìƒ‰ ê²°ê³¼)\n\n{disease_hints}"

        return base_prompt

    def generate_sql(self, user_query: str) -> SQLGenerationResult:
        """
        ìì—°ì–´ â†’ SQL ë³€í™˜ (RAG Pattern)

        Args:
            user_query: ì‚¬ìš©ì ìì—°ì–´ ìš”ì²­

        Returns:
            SQLGenerationResult
        """
        try:
            # 1. í‚¤ì›Œë“œ ì¶”ì¶œ
            keywords = self._extract_keywords(user_query)
            print(f"ğŸ“Œ ì¶”ì¶œëœ í‚¤ì›Œë“œ: {keywords}")

            # 2. === RAG Enhancement: ì§ˆë³‘ ì½”ë“œ ìë™ ê²€ìƒ‰ ===
            disease_codes = self._find_disease_codes(user_query)
            disease_hints = ""
            if disease_codes:
                print(f"ğŸ” RAG ì§ˆë³‘ ì½”ë“œ ë°œê²¬: {len(disease_codes)}ê°œ")
                hints = []
                for dc in disease_codes[:3]:  # ìµœëŒ€ 3ê°œë§Œ
                    hints.append(
                        f"- '{dc['keyword']}' â†’ `res_disease_code LIKE '{dc['pattern']}'` "
                        f"(ì˜ˆ: {dc['disease_name']} ì½”ë“œ: {dc['disease_code']})"
                    )
                disease_hints = "\n".join(hints)
                disease_hints += "\n\n**ì¤‘ìš”**: ìœ„ ì§ˆë³‘ ì½”ë“œë¥¼ ë°˜ë“œì‹œ ì‚¬ìš©í•˜ì„¸ìš”!"
                print(f"ğŸ’¡ ì§ˆë³‘ ì½”ë“œ íŒíŠ¸:\n{disease_hints}")

            # 3. === RAG Enhancement: Use unified SchemaLoader ===
            relevant_schema = self.schema_loader.get_relevant_schema(
                query=user_query,
                top_k=30,
                include_core_tables=True
            )
            print(f"ğŸ“Š ê´€ë ¨ í…Œì´ë¸”: {relevant_schema['í…Œì´ë¸”ëª…'].unique().tolist()}")
            print(f"ğŸ“Š ìŠ¤í‚¤ë§ˆ ì»¬ëŸ¼ ìˆ˜: {len(relevant_schema)}")

            # 4. ìŠ¤í‚¤ë§ˆ ì»¨í…ìŠ¤íŠ¸ ìƒì„± (unified formatter)
            schema_context = self.schema_loader.format_schema_for_llm(relevant_schema)

            # 5. ìœ ì‚¬ ì˜ˆì‹œ ì„ íƒ (Few-shot)
            examples = self._select_relevant_examples(user_query, keywords)
            print(f"ğŸ“š ì„ íƒëœ ì˜ˆì‹œ: {len(examples)}ê°œ")

            # 6. LLM í”„ë¡¬í”„íŠ¸ ìƒì„± (ì§ˆë³‘ ì½”ë“œ íŒíŠ¸ í¬í•¨)
            prompt = self._create_llm_prompt(user_query, schema_context, examples, disease_hints)

            # 7. Gemini API í˜¸ì¶œ
            response = self.gemini_model.generate_content(prompt)
            response_text = response.text.strip()

            # 8. JSON íŒŒì‹±
            if '```json' in response_text:
                response_text = response_text.split('```json')[1].split('```')[0].strip()
            elif '```' in response_text:
                response_text = response_text.split('```')[1].split('```')[0].strip()

            result = json.loads(response_text)

            # ë¡œê¹…
            if self.logger:
                log_nl2sql_generation(
                    self.logger,
                    user_query=user_query,
                    success=True,
                    rag_detected=bool(disease_codes),
                    disease_codes=[dc['pattern'] for dc in disease_codes] if disease_codes else []
                )

            return SQLGenerationResult(
                success=True,
                sql_query=result.get('sql', ''),
                analysis=result.get('analysis', {}),
                referenced_tables=result.get('analysis', {}).get('required_tables', []),
                relevant_examples=[ex['question'] for ex in examples]
            )

        except json.JSONDecodeError as e:
            error_msg = f"JSON íŒŒì‹± ì‹¤íŒ¨: LLM ì‘ë‹µ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤. {str(e)}"
            if self.logger:
                log_nl2sql_generation(self.logger, user_query, success=False, error=error_msg)
            return SQLGenerationResult(
                success=False,
                sql_query='',
                analysis={},
                error_message=error_msg
            )
        except KeyError as e:
            error_msg = f"ì‘ë‹µ êµ¬ì¡° ì˜¤ë¥˜: í•„ìˆ˜ í‚¤({str(e)})ê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤."
            if self.logger:
                log_nl2sql_generation(self.logger, user_query, success=False, error=error_msg)
            return SQLGenerationResult(
                success=False,
                sql_query='',
                analysis={},
                error_message=error_msg
            )
        except Exception as e:
            # ìƒì„¸í•œ ì—ëŸ¬ ì •ë³´ ì œê³µ
            error_type = type(e).__name__
            error_msg = f"SQL ìƒì„± ì‹¤íŒ¨ ({error_type}): {str(e)}"
            if self.logger:
                log_nl2sql_generation(self.logger, user_query, success=False, error=error_msg)
            return SQLGenerationResult(
                success=False,
                sql_query='',
                analysis={},
                error_message=error_msg
            )

    def refine_sql(
        self,
        original_query: str,
        current_sql: str,
        refinement_request: str
    ) -> SQLGenerationResult:
        """
        ê¸°ì¡´ SQLì„ ì‚¬ìš©ì í”¼ë“œë°±ì— ë”°ë¼ ê°œì„ 

        Args:
            original_query: ì›ë˜ ìì—°ì–´ ìš”ì²­
            current_sql: í˜„ì¬ ìƒì„±ëœ SQL
            refinement_request: ì‚¬ìš©ìì˜ ê°œì„  ìš”ì²­ (ì˜ˆ: "ì„œìš¸ ì§€ì—­ë§Œ í•„í„°ë§í•´ì£¼ì„¸ìš”")

        Returns:
            SQLGenerationResult: ê°œì„ ëœ SQL ê²°ê³¼
        """
        try:
            print(f"\nğŸ”„ SQL ê°œì„  ì‹œì‘...")
            print(f"  - ì›ë˜ ìš”ì²­: {original_query}")
            print(f"  - ê°œì„  ìš”ì²­: {refinement_request}")

            # 1. ê°œì„  ìš”ì²­ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ
            keywords = self._extract_keywords(refinement_request)
            print(f"  - ì¶”ì¶œëœ í‚¤ì›Œë“œ: {keywords}")

            # 2. ì§ˆë³‘ ì½”ë“œ ê²€ìƒ‰ (ê°œì„  ìš”ì²­ì—ì„œ)
            disease_codes = self._find_disease_codes(refinement_request)
            disease_hints = ""
            if disease_codes:
                print(f"  - ğŸ¯ RAG ì§ˆë³‘ ì½”ë“œ ë°œê²¬: {len(disease_codes)}ê°œ")
                disease_hints = self._format_disease_hints(disease_codes)

            # 3. ê´€ë ¨ ìŠ¤í‚¤ë§ˆ ì¶”ì¶œ (ì›ë˜ ìš”ì²­ + ê°œì„  ìš”ì²­ ê²°í•©)
            combined_query = original_query + " " + refinement_request
            schema_context = self.schema_loader.get_relevant_schema(combined_query, top_k=15)
            print(f"  - ìŠ¤í‚¤ë§ˆ: {len(schema_context)} rows")

            # 4. ê°œì„  í”„ë¡¬í”„íŠ¸ ìƒì„±
            prompt = self._create_refinement_prompt(
                original_query=original_query,
                current_sql=current_sql,
                refinement_request=refinement_request,
                schema_context=schema_context,
                disease_hints=disease_hints
            )

            # 5. Gemini API í˜¸ì¶œ
            response = self.gemini_model.generate_content(prompt)
            response_text = response.text.strip()

            # 6. JSON íŒŒì‹±
            if '```json' in response_text:
                response_text = response_text.split('```json')[1].split('```')[0].strip()
            elif '```' in response_text:
                response_text = response_text.split('```')[1].split('```')[0].strip()

            result = json.loads(response_text)

            # ë¡œê¹…
            if self.logger:
                log_nl2sql_generation(
                    self.logger,
                    user_query=f"[ê°œì„ ] {refinement_request}",
                    success=True,
                    rag_detected=bool(disease_codes),
                    disease_codes=[dc['pattern'] for dc in disease_codes] if disease_codes else []
                )

            print(f"âœ… SQL ê°œì„  ì™„ë£Œ")

            return SQLGenerationResult(
                success=True,
                sql_query=result.get('sql', ''),
                analysis=result.get('analysis', {}),
                referenced_tables=result.get('analysis', {}).get('required_tables', [])
            )

        except Exception as e:
            error_type = type(e).__name__
            error_msg = f"SQL ê°œì„  ì‹¤íŒ¨ ({error_type}): {str(e)}"
            if self.logger:
                log_nl2sql_generation(self.logger, f"[ê°œì„ ] {refinement_request}", success=False, error=error_msg)
            return SQLGenerationResult(
                success=False,
                sql_query='',
                analysis={},
                error_message=error_msg
            )

    def _create_refinement_prompt(
        self,
        original_query: str,
        current_sql: str,
        refinement_request: str,
        schema_context: pd.DataFrame,
        disease_hints: str
    ) -> str:
        """SQL ê°œì„ ìš© í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        # System prompt
        from pathlib import Path
        system_prompt_path = Path("prompts") / "nl2sql" / "system.txt"
        with open(system_prompt_path, 'r', encoding='utf-8') as f:
            system_prompt = f.read()

        # Schema context
        schema_text = self.schema_loader.format_schema_for_llm(schema_context)

        # ì˜ˆì‹œ ì¿¼ë¦¬ (ê°„ë‹¨í•˜ê²Œ 2ê°œë§Œ)
        examples = self.example_queries[:2]
        examples_text = "\n\n".join([
            f"**ì˜ˆì‹œ {i+1}:**\nì§ˆë¬¸: {ex['question']}\nSQL:\n```sql\n{ex['sql']}\n```"
            for i, ex in enumerate(examples)
        ])

        refinement_prompt = f"""
{system_prompt}

---

### ğŸ“Š ìŠ¤í‚¤ë§ˆ ì •ë³´
{schema_text}

### ğŸ’¡ Few-shot ì˜ˆì‹œ
{examples_text}

---

## ğŸ”„ SQL ê°œì„  ìš”ì²­

**ì›ë˜ ìš”ì²­:**
{original_query}

**í˜„ì¬ ìƒì„±ëœ SQL:**
```sql
{current_sql}
```

**ì‚¬ìš©ì ê°œì„  ìš”ì²­:**
{refinement_request}

{disease_hints}

---

## ğŸ¯ ê°œì„  ì§€ì¹¨

1. **í˜„ì¬ SQLì„ ê¸°ë°˜**ìœ¼ë¡œ ì‚¬ìš©ìì˜ ê°œì„  ìš”ì²­ì„ ë°˜ì˜í•˜ì„¸ìš”
2. **ê¸°ì¡´ ë¡œì§ì€ ìœ ì§€**í•˜ë˜, ìš”ì²­ëœ ë³€ê²½ ì‚¬í•­ë§Œ ì ìš©í•˜ì„¸ìš”
3. **ì§ˆë³‘ ì½”ë“œ íŒíŠ¸**ê°€ ì œê³µëœ ê²½ìš° ë°˜ë“œì‹œ í™œìš©í•˜ì„¸ìš”
4. **ì „ì²´ SQLì„ ë‹¤ì‹œ ìƒì„±**í•˜ì„¸ìš” (ë¶€ë¶„ ìˆ˜ì •ì´ ì•„ë‹˜)

ì‘ë‹µ í˜•ì‹ (JSON):
```json
{{
  "sql": "ê°œì„ ëœ ì „ì²´ SQL ì¿¼ë¦¬ (Spark SQL)",
  "analysis": {{
    "required_tables": ["í…Œì´ë¸”1", "í…Œì´ë¸”2"],
    "key_conditions": ["ì¡°ê±´1", "ì¡°ê±´2"],
    "explanation": "ê°œì„  ë‚´ìš© ì„¤ëª…"
  }}
}}
```
"""
        return refinement_prompt


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸
    generator = NL2SQLGenerator()

    test_queries = [
        "ê³ í˜ˆì•• í™˜ìì˜ ì„±ë³„ ë¶„í¬ë¥¼ ë³´ì—¬ì£¼ì„¸ìš”",
        "ë‹¹ë‡¨ë³‘ í™˜ìì—ê²Œ ê°€ì¥ ë§ì´ ì²˜ë°©ëœ ì•½ë¬¼ TOP 10ì„ ì•Œë ¤ì£¼ì„¸ìš”",
        "ì„œìš¸ ì§€ì—­ 3ì°¨ ë³‘ì›ì—ì„œ ì¹˜ë£Œë°›ì€ ì•” í™˜ìëŠ” ëª‡ ëª…ì¸ê°€ìš”?",
    ]

    for query in test_queries:
        print(f"\n{'='*70}")
        print(f"ğŸ” Query: {query}")
        print(f"{'='*70}")

        result = generator.generate_sql(query)

        if result.success:
            print(f"\nğŸ“Š ë¶„ì„:")
            for key, value in result.analysis.items():
                print(f"  - {key}: {value}")

            print(f"\nğŸ’¡ ì°¸ê³  ì˜ˆì‹œ: {result.relevant_examples}")
            print(f"\nğŸ“ ìƒì„±ëœ SQL:")
            print(result.sql_query)
        else:
            print(f"\nâŒ ì˜¤ë¥˜: {result.error_message}")
